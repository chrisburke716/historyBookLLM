{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae538c42",
   "metadata": {},
   "source": [
    "# RAG Response Evals: Build Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e0402",
   "metadata": {},
   "source": [
    "Build a dataset using a combination of user queries and synthetic LLM-generated queries.\n",
    "\n",
    "Reuse data from previous 'vector search cutoff' experiments.\n",
    "- LLM generated queries tended to be more complex questions than user queries.\n",
    "- Aim for 100 questions, 50 pure LLM-generated, and 50 user + few-shot LLM 'user-like' queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1089bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e647d8b",
   "metadata": {},
   "source": [
    "## Load previous queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc7f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_csv(\"retrieval_relevance_evaluations_user_queries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3cca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synth = pd.read_csv(\"retrieval_relevance_evaluations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2551ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_queries = list(df_user['query'].unique())\n",
    "synth_queries = list(df_synth['query'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5769d77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_queries), len(synth_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63806f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What were the first civilizations?',\n",
       " 'when did julius cesar rule?',\n",
       " 'how does the author define barbarians?',\n",
       " 'why are Sunnis and Shia called that?',\n",
       " 'who were the guptas?',\n",
       " 'name the Chinese dynasties',\n",
       " 'what was hellenization?',\n",
       " 'Can you tell me about groups that moved into europe during the roman empire?',\n",
       " 'Who were the Magyars?',\n",
       " 'who were the scythians?',\n",
       " \"what does 'doge' mean?\",\n",
       " 'tell me about the antonine age in rome',\n",
       " 'Tell me about the Roman Empire',\n",
       " 'who were the Seljuks?',\n",
       " 'What groups had interactions with the Magyars?',\n",
       " 'What were the main causes of World War I?']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032df08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67aba9d5",
   "metadata": {},
   "source": [
    "# Generate more queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use openai llm to generate a set of questions to ask about a world history book\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class HistoryQuestions(BaseModel):\n",
    "    questions: List[str] = Field(description=\"List of world history questions\")\n",
    "\n",
    "def format_few_shot_examples(queryList):\n",
    "    return \"\\n\".join([f\"- {q}\" for q in queryList])\n",
    "\n",
    "@traceable\n",
    "def generate_simple_history_questions_few_shot(good_example_list, bad_example_list, num_questions=20):\n",
    "    # Initialize parser and LLM\n",
    "    parser = JsonOutputParser(pydantic_object=HistoryQuestions)\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.8)\n",
    "    \n",
    "    # Create prompt template\n",
    "    prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a world history expert.\n",
    "        \n",
    "    Generate {num_questions} diverse, specific questions that could be asked about a comprehensive world history book. \n",
    "    \n",
    "    The questions should cover:\n",
    "    - Different time periods (ancient, medieval, modern, contemporary)\n",
    "    - Various civilizations and regions (Europe, Asia, Africa, Americas, Middle East)\n",
    "\n",
    "    Below is a set of good example questions. These are simple, factual questions, not complex analytical ones. Try to mimic this style.\n",
    "    Good examples:\n",
    "    {good_examples}\n",
    "\n",
    "    Below is a set of bad example questions. These are more complex and analytical. Try to avoid this style.\n",
    "    Bad examples:\n",
    "    {bad_examples}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create LCEL chain\n",
    "    # example_formatter = RunnableLambda(lambda x: {\"examples\": format_few_shot_examples(x[\"example_list\"])})\n",
    "    example_formatter_1 = RunnablePassthrough.assign(good_examples=lambda x: format_few_shot_examples(x[\"example_list\"]))\n",
    "    example_formatter_2 = RunnablePassthrough.assign(bad_examples=lambda x: format_few_shot_examples(x[\"example_list\"]))\n",
    "\n",
    "    chain = example_formatter_1 | example_formatter_2 | prompt | llm | parser\n",
    "\n",
    "    # Execute chain\n",
    "    result = chain.invoke({\n",
    "        \"example_list\": example_list,\n",
    "        \"num_questions\": num_questions,\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    })\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "392b5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_queries_selected = [user_queries[0],user_queries[1],user_queries[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f29600e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What were the key factors that led to the fall of the Western Roman Empire?',\n",
       " 'How did the spread of Islam in the 7th century influence trade and cultural exchanges across Africa and Europe?',\n",
       " 'What were the primary motivations behind the European Age of Exploration during the 15th and 16th centuries?']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_queries[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ca9a3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': ['What factors led to the rise and fall of the Ancient Egyptian civilization?',\n",
       "  'During which centuries did the Mongol Empire reach its peak, and who were its most notable leaders?',\n",
       "  'What were the primary causes and outcomes of the Industrial Revolution in Europe?',\n",
       "  'How did the Meiji Restoration transform Japan in the late 19th century?',\n",
       "  'What significant events and changes occurred in Africa during the decolonization period of the mid-20th century?']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_simple_history_questions_few_shot(example_list=user_queries_selected, num_questions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a69fe6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What were the first civilizations?',\n",
       " 'when did julius cesar rule?',\n",
       " 'how does the author define barbarians?',\n",
       " 'why are Sunnis and Shia called that?',\n",
       " 'who were the guptas?',\n",
       " 'name the Chinese dynasties',\n",
       " 'what was hellenization?',\n",
       " 'Can you tell me about groups that moved into europe during the roman empire?',\n",
       " 'Who were the Magyars?',\n",
       " 'who were the scythians?',\n",
       " \"what does 'doge' mean?\",\n",
       " 'tell me about the antonine age in rome',\n",
       " 'Tell me about the Roman Empire',\n",
       " 'who were the Seljuks?',\n",
       " 'What groups had interactions with the Magyars?',\n",
       " 'What were the main causes of World War I?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38be460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "history-book-py3.11 (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
