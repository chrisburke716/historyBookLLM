{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae538c42",
   "metadata": {},
   "source": [
    "# RAG Response Evals: Build Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e0402",
   "metadata": {},
   "source": [
    "Build a dataset using a combination of user queries and synthetic LLM-generated queries.\n",
    "\n",
    "Reuse data from previous 'vector search cutoff' experiments.\n",
    "- LLM generated queries tended to be more complex questions than user queries.\n",
    "- Aim for 100 questions, 50 pure LLM-generated, and 50 user + few-shot LLM 'user-like' queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1089bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e647d8b",
   "metadata": {},
   "source": [
    "## Load previous queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc7f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_csv(\"retrieval_relevance_evaluations_user_queries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3cca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synth = pd.read_csv(\"retrieval_relevance_evaluations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2551ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_queries = list(df_user['query'].unique())\n",
    "synth_queries = list(df_synth['query'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5769d77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_queries), len(synth_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63806f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What were the first civilizations?',\n",
       " 'when did julius cesar rule?',\n",
       " 'how does the author define barbarians?',\n",
       " 'why are Sunnis and Shia called that?',\n",
       " 'who were the guptas?',\n",
       " 'name the Chinese dynasties',\n",
       " 'what was hellenization?',\n",
       " 'Can you tell me about groups that moved into europe during the roman empire?',\n",
       " 'Who were the Magyars?',\n",
       " 'who were the scythians?',\n",
       " \"what does 'doge' mean?\",\n",
       " 'tell me about the antonine age in rome',\n",
       " 'Tell me about the Roman Empire',\n",
       " 'who were the Seljuks?',\n",
       " 'What groups had interactions with the Magyars?',\n",
       " 'What were the main causes of World War I?']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032df08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67aba9d5",
   "metadata": {},
   "source": [
    "## Generate more queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use openai llm to generate a set of questions to ask about a world history book\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class HistoryQuestions(BaseModel):\n",
    "    questions: List[str] = Field(description=\"List of world history questions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4b896d",
   "metadata": {},
   "source": [
    "### Simple questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac350c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_few_shot_examples(queryList):\n",
    "    return \"\\n\".join([f\"- {q}\" for q in queryList])\n",
    "\n",
    "@traceable\n",
    "def generate_simple_history_questions_few_shot(good_example_list, bad_example_list, num_questions=20):\n",
    "    # Initialize parser and LLM\n",
    "    parser = JsonOutputParser(pydantic_object=HistoryQuestions)\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.8)\n",
    "    \n",
    "    # Create prompt template\n",
    "    prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a world history expert.\n",
    "        \n",
    "    Generate {num_questions} diverse, specific questions that could be asked about a comprehensive world history book. \n",
    "    \n",
    "    The questions should cover:\n",
    "    - Different time periods (ancient, medieval, modern, contemporary)\n",
    "    - Various civilizations and regions (Europe, Asia, Africa, Americas, Middle East)\n",
    "\n",
    "    Below is a set of good example questions. These are simple, factual questions, not complex analytical ones. Try to mimic this style.\n",
    "    Good examples:\n",
    "    {good_examples}\n",
    "\n",
    "    Below is a set of bad example questions. These are more complex and analytical. Try to avoid this style.\n",
    "    Bad examples:\n",
    "    {bad_examples}\n",
    "\n",
    "    While the questions should be simple, they should still cover esoteric topics.\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create LCEL chain\n",
    "    # example_formatter = RunnableLambda(lambda x: {\"examples\": format_few_shot_examples(x[\"example_list\"])})\n",
    "    example_formatter_1 = RunnablePassthrough.assign(good_examples=lambda x: format_few_shot_examples(x[\"good_example_list\"]))\n",
    "    example_formatter_2 = RunnablePassthrough.assign(bad_examples=lambda x: format_few_shot_examples(x[\"bad_example_list\"]))\n",
    "\n",
    "    chain = example_formatter_1 | example_formatter_2 | prompt | llm | parser\n",
    "\n",
    "    # Execute chain\n",
    "    result = chain.invoke({\n",
    "        \"good_example_list\": good_example_list,\n",
    "        \"bad_example_list\": bad_example_list,\n",
    "        \"num_questions\": num_questions,\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    })\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "392b5c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What were the first civilizations?',\n",
       " 'when did julius cesar rule?',\n",
       " 'why are Sunnis and Shia called that?']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_queries_selected = [user_queries[0],user_queries[1],user_queries[3]]\n",
    "user_queries_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f29600e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What were the key factors that led to the fall of the Western Roman Empire?',\n",
       " 'How did the spread of Islam in the 7th century influence trade and cultural exchanges across Africa and Europe?',\n",
       " 'What were the primary motivations behind the European Age of Exploration during the 15th and 16th centuries?']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_queries[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ca9a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_synth_queries = generate_simple_history_questions_few_shot(good_example_list=user_queries_selected, bad_example_list=synth_queries[:3], num_questions=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a38be460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': ['What were the major inventions of the Bronze Age?',\n",
       "  'Who was the first emperor of China?',\n",
       "  'When did the Byzantine Empire fall?',\n",
       "  'What is the significance of the Indus Valley Civilization?',\n",
       "  'Who founded the Mali Empire?',\n",
       "  'What were the key features of the Aztec civilization?',\n",
       "  'When did the Mongol Empire reach its greatest extent?',\n",
       "  'Who was the ruler of the Ottoman Empire during the Siege of Vienna?',\n",
       "  \"What were the causes of the Thirty Years' War?\",\n",
       "  'Who was the first president of the United States?',\n",
       "  'When did the Industrial Revolution begin?',\n",
       "  'What was the Meiji Restoration?',\n",
       "  'Who was the leader of the Zulu Kingdom during the Anglo-Zulu War?',\n",
       "  'What was the significance of the Mayan calendar?',\n",
       "  'When did the Berlin Wall fall?',\n",
       "  'Who was the last Tsar of Russia?',\n",
       "  'What was the primary language of the Sumerians?',\n",
       "  'Who was the founder of the Persian Empire?',\n",
       "  'When was the Magna Carta signed?',\n",
       "  'What was the main religion of ancient Egypt?',\n",
       "  'Who led the Haitian Revolution?',\n",
       "  'When did India gain independence from Britain?',\n",
       "  'What was the significance of the Silk Road?',\n",
       "  'Who was the first female pharaoh of Egypt?',\n",
       "  'What were the Punic Wars?',\n",
       "  'When did the Black Death occur in Europe?',\n",
       "  'Who was the leader of the Soviet Union during World War II?',\n",
       "  'What was the cultural significance of the Renaissance?',\n",
       "  'Who was Genghis Khan?',\n",
       "  'When did the Taiping Rebellion occur?',\n",
       "  'What was the main purpose of the Great Wall of China?',\n",
       "  'Who was the first European to reach India by sea?',\n",
       "  'What were the primary crops of the Inca Empire?',\n",
       "  'When did apartheid end in South Africa?']}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_synth_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5716c",
   "metadata": {},
   "source": [
    "### Complex questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42376bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# reused from 'investigate_vector_search_cutoff.ipynb'\n",
    "def generate_history_questions(num_questions=20):\n",
    "    # Initialize parser and LLM\n",
    "    parser = JsonOutputParser(pydantic_object=HistoryQuestions)\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.8)\n",
    "    \n",
    "    # Create prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a world history expert who creates thoughtful, educational questions.\"),\n",
    "        (\"user\", \"\"\"Generate {num_questions} diverse, specific questions that could be asked about a comprehensive world history book. \n",
    "    \n",
    "    The questions should cover:\n",
    "    - Different time periods (ancient, medieval, modern, contemporary)\n",
    "    - Various civilizations and regions (Europe, Asia, Africa, Americas, Middle East)\n",
    "    - Different types of historical topics (political events, cultural developments, economic systems, wars, social movements, technological advances)\n",
    "    - Both broad conceptual questions and specific factual questions\n",
    "    \n",
    "    Make the questions natural and realistic - the kind a student or researcher might ask when studying world history.\n",
    "    \n",
    "    Examples of good questions:\n",
    "    - What were the main causes of World War I?\n",
    "    - How did the Silk Road impact trade between East and West?\n",
    "    - What role did the printing press play in the Renaissance?\n",
    "    \n",
    "    {format_instructions}\"\"\")\n",
    "    ])\n",
    "    \n",
    "    # Create LCEL chain\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    # Execute chain\n",
    "    result = chain.invoke({\n",
    "        \"num_questions\": num_questions,\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0db988c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all 50, instead of augmenting old ones (avoid overlap)\n",
    "complex_synth_queries = generate_history_questions(num_questions=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9beced0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complex_synth_queries[\"questions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f5ce37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_synth_queries[\"questions\"] = complex_synth_queries[\"questions\"][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef2098c",
   "metadata": {},
   "source": [
    "## Combine into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb37f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_queries = pd.DataFrame(user_queries, columns=[\"query\"])\n",
    "df_user_queries['source'] = 'user'\n",
    "df_user_queries['complexity'] = 'simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "43cb6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_synth = pd.DataFrame(simple_synth_queries[\"questions\"], columns=[\"query\"])\n",
    "df_simple_synth['source'] = 'synth'\n",
    "df_simple_synth['complexity'] = 'simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e9745ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complex_synth = pd.DataFrame(complex_synth_queries[\"questions\"], columns=[\"query\"])\n",
    "df_complex_synth['source'] = 'synth'\n",
    "df_complex_synth['complexity'] = 'complex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4657d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df_user_queries, df_simple_synth, df_complex_synth], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e4bd2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv(\"eval_dataset_queries.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ab1af",
   "metadata": {},
   "source": [
    "## Upload to Langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "17e2361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset in langsmith\n",
    "from langsmith import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0bb38582",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "dataset_name = \"History Book Eval Queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "abd8456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.delete_dataset(dataset_name=\"History Book Eval Queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2ed8b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.create_dataset(\n",
    "  dataset_name=dataset_name, description=\"A dataset of queries for evaluating a history book retrieval system.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd5d7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  {\n",
    "    \"inputs\": {\"question\": row.query},\n",
    "    \"metadata\": {\"source\": row.source, \"complexity\": row.complexity},\n",
    "  }\n",
    "  for _, row in df_full.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8adbb902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['45d27b47-d078-4ff0-b0c4-23905b1c849d',\n",
       "  '8708d042-17f6-4a1a-baa4-4ec6bb22ee95',\n",
       "  'b9b63ea1-0783-4af3-b368-c1202c698f10',\n",
       "  'cd024e14-7330-4853-887a-1fb1980d806e',\n",
       "  '4c8a2461-458d-41a0-a107-1a28d91dba96',\n",
       "  'ba1d39c2-7973-49a3-927f-e5d1bfbd9490',\n",
       "  '9e34314f-e8ab-4158-bd97-bbe5b218672c',\n",
       "  '35ff45df-16b5-476f-af90-4c16eedfb843',\n",
       "  'c422022b-5b7f-4366-b25d-04f95d93326f',\n",
       "  '3a969e37-67ae-4b56-a6f0-f76296c845c2',\n",
       "  '56866db6-7bf4-45f1-8f98-359562b9a78a',\n",
       "  'b0551619-9acd-46d8-82e5-546a6e637e3e',\n",
       "  'dadf947a-c1f5-49bc-a485-4e705a9dd555',\n",
       "  'ba306d39-9dd2-464a-8c4e-8f451ceb93dc',\n",
       "  'c7028512-14ac-4fca-8783-e5803c44dc58',\n",
       "  '11285b73-c420-40cd-9f68-e0aa6da5a193',\n",
       "  '49b4a759-675f-4d55-afd3-2359c70520c6',\n",
       "  '6d8ad2e6-7345-4623-b109-70770db02e4d',\n",
       "  '884ff068-a67d-413c-a8de-d6c0ac240205',\n",
       "  '776e8ad0-e481-4c71-a6ee-24e3ff84eb65',\n",
       "  '1c1be83f-d0b8-4a1b-bb8d-eac93fa4e26f',\n",
       "  '2ac3cf60-1a93-4e03-a7d5-43e33909cc40',\n",
       "  '60c37788-2482-49ba-8e38-a479279bb804',\n",
       "  '79936e54-0faf-4bb1-81ea-7c6e40896b64',\n",
       "  'ab31fee0-83ae-4774-9791-854b5c546985',\n",
       "  '5fe5fed0-2eb2-4a1e-9f6e-ce6d641056b2',\n",
       "  '1eaeaa2a-7a29-4276-87a0-bf1800ed416c',\n",
       "  'b517d844-cfcf-4d3b-8951-f5529fe1dc20',\n",
       "  '93a742ad-0467-4c5c-9323-7a05f70a1feb',\n",
       "  'b81fcc93-2599-48d1-aa66-55ddaefc2f94',\n",
       "  '860041f0-3efc-481f-a079-76501e9d2c3f',\n",
       "  '746f1338-59ba-4d5d-ba3e-132d25b8b9b8',\n",
       "  'dc82780b-709c-4570-9373-75cc070ed814',\n",
       "  '0c20cb54-c8d4-47a8-9146-1533976b71a1',\n",
       "  'a672ed6a-66e3-4dbd-9ad4-7badc6e42553',\n",
       "  '8162309f-4221-4d6d-a9f2-4dd292b7444f',\n",
       "  'f973520b-9e6a-4284-90b2-2e95e6be69b8',\n",
       "  'c7dae81e-80a0-49ad-b541-74b7de7e61d0',\n",
       "  'aa4c7862-5822-49a0-9f55-0c05908bc61a',\n",
       "  '5299acba-7bb1-4e34-88d0-b03097899c89',\n",
       "  '34c3bab2-40d3-42bd-ba52-dc342273b274',\n",
       "  '5702326d-85d6-4199-8ed4-2a6689a181d6',\n",
       "  '15530dda-42dc-476e-89dc-846ed50e6f36',\n",
       "  '9f3d8ad7-a3ad-4aa3-8b59-d25b70bf77d0',\n",
       "  '2937c1ca-40ec-497b-8b9a-ddea17b1e93d',\n",
       "  '928106e4-7dda-4848-895c-a423d1d1a685',\n",
       "  'f4cd7271-1fbf-4af7-8853-5ed019d1d956',\n",
       "  '78e810bd-b758-41d4-8e15-5f5f66110a81',\n",
       "  'b51fe501-e552-4895-8d96-02332806e927',\n",
       "  '9f512ff2-cf50-4bc8-98a3-c7ce6f81576a',\n",
       "  '416d968f-365b-4b04-afd2-1efa6511fb35',\n",
       "  '924050a7-c530-423f-b5e5-505242593e99',\n",
       "  '6141c929-5228-4754-a04b-de80288c4900',\n",
       "  'd9f8cfd1-703d-4474-b4cc-de40d89ef405',\n",
       "  '0feebc2a-dec6-45ce-8ef5-0b0cbcf5695e',\n",
       "  '10a733e3-42da-4c00-a17c-92bdba9188cd',\n",
       "  'af06228d-758a-44d1-ad5d-ed385a5edf4f',\n",
       "  '90f756d5-a4c4-4128-b676-9b24c846d930',\n",
       "  '779e4b46-c7b3-4469-a65c-4fcb42548a69',\n",
       "  '8823091e-9fd4-4b91-ae95-300b2ca9b3a0',\n",
       "  '357585e1-33ea-40da-8a4e-9e4950542ee0',\n",
       "  'a868ffae-cae7-4f2f-9ee4-0cad7e6cfbe5',\n",
       "  '4c72bf60-6ed1-489f-a205-f4aa07a55585',\n",
       "  '19cd596c-b8e9-45a5-9d82-5752803b4b6c',\n",
       "  '0b02dfdb-9835-4d1c-ae2c-22ded9cb39f5',\n",
       "  '9413993b-7f25-4fd0-b1c5-3050cc821eb6',\n",
       "  'ab837ce6-0028-4474-8e4e-32e78c358026',\n",
       "  '8c3b7e6d-2e3a-4914-a758-9f011d39a9be',\n",
       "  '21cf438f-b846-4063-8d75-f94d0afb6362',\n",
       "  'bba3b2aa-6fc8-4cae-a199-64a21cafa64e',\n",
       "  '0fe660fb-e78b-493c-ba7d-356014fd29ed',\n",
       "  'bbdd0f01-42b5-4172-812d-7eaaece071fe',\n",
       "  'cc368968-9870-4d1d-b222-87abb52b9827',\n",
       "  '39e22b4c-41a1-41b8-9cf5-2139b786fe03',\n",
       "  '2a8e15e3-0215-4f17-b973-cd328b409dd5',\n",
       "  '24b00642-19af-4899-9d5a-435a9d37d2b8',\n",
       "  '84dfa092-e8ff-47ae-8a55-455be0597861',\n",
       "  '6db70e6e-e327-4c96-b526-62c69c53c7d5',\n",
       "  '285cc2d0-ade5-43e1-82d5-f57c42b87373',\n",
       "  'd9206c83-cc41-4f00-ace9-766debcdb331',\n",
       "  'eaa45748-7067-4a7e-a8cb-39244cf25fe4',\n",
       "  '3e34bde3-9d77-42c4-89ce-e52847e78bb2',\n",
       "  'e8804fcc-504f-4cdc-9b74-5c5738efa16e',\n",
       "  '74aeec4d-5dcf-4efa-8b59-71291f27c1a0',\n",
       "  '0e8e6dee-e3f2-48cd-a0ef-b21a06c84a47',\n",
       "  '247a2b6f-aca8-4f69-abd3-ee6d4dbc7596',\n",
       "  '6ddef74b-9d01-4fa2-b700-65f668483a27',\n",
       "  '23f80b65-a681-469e-aceb-0ae4b4c42818',\n",
       "  'e6c61906-97fd-450a-b9fe-5fb58e07c2f8',\n",
       "  '1abc47fa-17f4-4917-8391-03fe7e510069',\n",
       "  '8823b2cb-3f20-44ab-bfbd-d6a93699b012',\n",
       "  '1d2c80c1-f89c-44d4-b2e2-60eb35138aec',\n",
       "  '28d7e5ad-93bb-4725-9557-08a9abe90bba',\n",
       "  '1d41e55f-d29f-4e28-bc39-23b6eaffff5d',\n",
       "  'af6ffbee-509c-47d6-a4d1-6419940154e3',\n",
       "  '55df0f39-63c6-4ca0-b473-88f4b9435958',\n",
       "  '7edcaf61-ab38-49e2-ba3e-a9bf41ade97e',\n",
       "  '772a3d65-ad3f-458d-a654-c127b7fcfb70',\n",
       "  '5aac60a3-a18e-4ba0-be30-4de9620a58be',\n",
       "  '59132c18-d440-4f89-80d7-3defa6d196a3'],\n",
       " 'count': 100}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_examples(\n",
    "  dataset_id=dataset.id,\n",
    "  examples=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bfcd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "history-book-py3.11 (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
