{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph Experiment v2\n",
    "\n",
    "**Goal**: Extract entities and relationships from historical text, normalize them, and visualize as a knowledge graph.\n",
    "\n",
    "**Approach**: Hybrid normalization pipeline\n",
    "1. **LLM Extraction** - GPT structured outputs to extract entities + relationships per paragraph\n",
    "2. **ID Assignment** - UUIDs with bidirectional entity↔relationship links\n",
    "3. **Rule-Based Normalization** - Exact name + alias matching to collapse obvious duplicates\n",
    "4. **Embedding Similarity** - Compute on rule-normalized entities (not raw) to find remaining merge candidates\n",
    "5. **LLM Merge (incremental)** - Evaluate candidates in order of similarity, merge as we go to avoid redundant comparisons\n",
    "6. **Graph Construction & Visualization** - NetworkX + PyVis\n",
    "\n",
    "**Key insight**: Running LLM normalization on all raw entity pairs is an N² problem that doesn't scale. The hybrid approach reduces this dramatically:\n",
    "- Rule-based pass collapses ~30-40% of entities (exact name + alias matches)\n",
    "- Embedding similarity on the reduced set finds only the ambiguous candidates\n",
    "- Incremental LLM merge skips pairs already in the same group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import uuid as uuid_module\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# Suppress Pydantic V2 deprecation warnings from LangChain's tracer\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from pydantic import BaseModel, Field\n",
    "from pyvis.network import Network\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "CONFIG = {\n",
    "    \"extraction_model\": \"gpt-4.1-mini\",\n",
    "    \"extraction_temperature\": 0.0,\n",
    "    \"merge_model\": \"gpt-5-mini\",\n",
    "    \"merge_temperature\": 0.0,\n",
    "    \"embedding_model\": \"text-embedding-3-small\",\n",
    "    \"similarity_threshold\": 0.65,\n",
    "    \"similarity_method\": \"levenshtein\",  # \"cosine\" or \"levenshtein\"\n",
    "    \"levenshtein_threshold\": 0.6,\n",
    "    \"max_llm_candidates\": 100,\n",
    "    \"reasoning_effort\": \"minimal\",  # for models that support it\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 85 paragraphs\n",
      "  [0] page 317, para 0: All around the western Mediterranean shores and across wide tracts of western Eu...\n",
      "  [1] page 318, para 1: Rome itself, the values it embodied and imposed, the notion of what was one day ...\n",
      "  [2] page 318, para 2: It was believed to have deep roots. Romans said their city was founded by one Ro...\n",
      "  [3] page 318, para 3: In spite of a rich archaeological record, with many inscriptions and much schola...\n",
      "  [4] page 318, para 4: There were probably still at that time some aboriginal natives among them whose ...\n",
      "  [5] page 319, para 5: In the sixth century BC the Etruscans were installed in an important bridgehead ...\n",
      "  [6] page 321, para 6: Fertilization by Greek influence was perhaps its most important inheritance, but...\n",
      "  [7] page 321, para 7: The Roman republic was to last for more than 450 years, and even after that its ...\n",
      "  [8] page 321, para 8: Broadly speaking, the changes of republican times were symptoms and results of t...\n",
      "  [9] page 322, para 9: Internal politics were rooted in arrangements originally meant to make impossibl...\n",
      "  [10] page 322, para 10: Somewhat surprisingly, the internal struggles of the early republic seem to have...\n",
      "  [11] page 322, para 11: Two consuls had replaced the last kings at the end of the sixth century BC. Appo...\n",
      "  [12] page 323, para 12: ‘Plebs’, in any case, is a misleadingly simple term. The word stood for differen...\n",
      "  [13] page 323, para 13: The free citizens who made up the bulk of the population of the early republic w...\n",
      "  [14] page 324, para 14: There was a persistent tendency, accelerating rapidly in the third and second ce...\n",
      "  [15] page 324, para 15: This was not only because wealth came to count for so much in Roman politics. It...\n",
      "  [16] page 324, para 16: But the main restriction on the traditional rulers lay in the ten elected Tribun...\n",
      "  [17] page 325, para 17: The constitutional arrangements of the early republic were thus very complicated...\n",
      "  [18] page 326, para 18: Etruscan hegemony in central Italy, the richest and most developed part of the p...\n",
      "  [19] page 326, para 19: Roman military power grew as did the number of subjected states. The republic’s ...\n",
      "  [20] page 326, para 20: Rome was now at last face to face with the western Greek cities. Syracuse was by...\n",
      "  [21] page 326, para 21: They form a duel of more than a century. Their name comes from the Roman renderi...\n",
      "  [22] page 327, para 22: Carthage, and western Sicily and Sardinia became the first Roman provinces, a mo...\n",
      "  [23] page 327, para 23: This was only round one. As the end of the third century approached, the final o...\n",
      "  [24] page 327, para 24: With no resources save her own exertions, and the great advantage that Hannibal ...\n",
      "  [25] page 328, para 25: This battle settled more than a war; it decided the fate of the whole western Me...\n",
      "  [26] page 328, para 26: At the end of the second Punic War it is tempting to imagine Rome at a parting o...\n",
      "  [27] page 329, para 27: Another change in Roman attitudes was not yet complete, but was beginning to be ...\n",
      "  [28] page 329, para 28: The twists and turns are complicated, but the main stages of Roman expansion in ...\n",
      "  [29] page 330, para 29: Thus was the empire made by the republic. Like all empires, but perhaps more obv...\n",
      "  [30] page 330, para 30: Empire inevitably had political consequences at home. In the first place it made...\n",
      "  [31] page 331, para 31: Another constitutional weakness arose because the principle of annual election o...\n",
      "  [32] page 331, para 32: Another change brought by empire was a further spread of Hellenization. Here the...\n",
      "  [33] page 332, para 33: With empire the contact became direct and the flow of Hellenistic influence mani...\n",
      "  [34] page 332, para 34: Rome’s greatest triumph rested on the bringing of peace. In a second great Helle...\n",
      "  [35] page 333, para 35: It is convenient to finish the story of the spread of the rule of the republic t...\n",
      "  [36] page 333, para 36: Ironically, the counterpoint of this continuing and apparently irresistible succ...\n",
      "  [37] page 334, para 37: The second problem was a change in the army. The legions had more than 400 years...\n",
      "  [38] page 335, para 38: The widening gap between rich and poor in central Italy as peasant farming gave ...\n",
      "  [39] page 336, para 39: The final plunge of the republic into confusion was precipitated in 112 BC by a ...\n",
      "  [40] page 336, para 40: One former supporter and protégé of Sulla was a young man whose name has passed ...\n",
      "  [41] page 337, para 41: In 59 BC another aristocrat, the nephew of Marius’s wife, had been elected consu...\n",
      "  [42] page 337, para 42: Some senators suddenly became alarmed when this formidable man wished to remain ...\n",
      "  [43] page 338, para 43: In extremis the Senate called on Pompey to defend the republic. Without forces i...\n",
      "  [44] page 339, para 44: Brilliance like this was not just a matter of winning battles. Brief though Caes...\n",
      "  [45] page 340, para 45: Fifteen months later Caesar was dead, struck down in the Senate on 15 March 44 B...\n",
      "  [46] page 340, para 46: His murderers had no answer to the problems which Caesar had not had the time, a...\n",
      "  [47] page 340, para 47: If the Greek contribution to civilization was essentially mental and spiritual, ...\n",
      "  [48] page 341, para 48: Though a Caesar, Octavian came from a junior branch. From Julius he inherited at...\n",
      "  [49] page 341, para 49: This was the end of civil war. Octavian returned to become consul. He had every ...\n",
      "  [50] page 342, para 50: As the years passed Augustus’s power still grew. The Senate accorded him a right...\n",
      "  [51] page 342, para 51: The political reality masked by this supremacy was the rise to domination within...\n",
      "  [52] page 343, para 52: Augustus intended to be succeeded by a member of his own family. Although he res...\n",
      "  [53] page 343, para 53: The rulers of the classical world did not usually live easy lives. Some Roman em...\n",
      "  [54] page 344, para 54: When Vespasian’s younger son was murdered in AD 96 this upstart house came to an...\n",
      "  [55] page 344, para 55: By this time, the emperors ruled a far larger area than had Augustus. In the nor...\n",
      "  [56] page 345, para 56: Elsewhere, Roman rule still advanced. In AD 43 Claudius began the conquest of Br...\n",
      "  [57] page 345, para 57: Rome had first faced Parthia on the Euphrates when Sulla’s army campaigned there...\n",
      "  [58] page 345, para 58: After this, the eastern frontier on the Euphrates was to remain undisturbed for ...\n",
      "  [59] page 346, para 59: Augustus was able to obtain the return of the Roman standards taken from Crassus...\n",
      "  [60] page 346, para 60: It was the Roman boast that their new subjects all benefited from the extension ...\n",
      "  [61] page 346, para 61: The empire was a huge area and required the solution of problems of government w...\n",
      "  [62] page 347, para 62: The co-operation of the subject peoples was tempted with a bait. First the repub...\n",
      "  [63] page 347, para 63: This was an outstanding instance of Roman power of assimilation. The empire and ...\n",
      "  [64] page 348, para 64: Roman élite or a professional bureaucracy, but by a constitutional system which ...\n",
      "  [65] page 348, para 65: Already Hellenistic civilization had achieved a remarkable mixing of East and We...\n",
      "  [66] page 348, para 66: It may be that in this lies one clue to the peculiar tenor of Roman culture. Per...\n",
      "  [67] page 349, para 67: Only in two practical fields were the Romans to be great innovators – law and en...\n",
      "  [68] page 350, para 68: Roman technical accomplishment was stamped on an area stretching from the Black ...\n",
      "  [69] page 350, para 69: In part this was the simple expression of the social realities on which the empi...\n",
      "  [70] page 351, para 70: Unfortunately, though easy to recognize, the realities of wealth in Rome still r...\n",
      "  [71] page 351, para 71: The Roman pattern was reflected in all the great cities of the empire. It was ce...\n",
      "  [72] page 351, para 72: In this civilization the omnipresence of the amphitheatre is a standing reminder...\n",
      "  [73] page 354, para 73: Another aspect of the brutality at the heart of Roman society was, of course, fa...\n",
      "  [74] page 354, para 74: Much of what we know about popular mentality before modern times is known throug...\n",
      "  [75] page 354, para 75: The civic authorities were everywhere responsible for the rites, as they were re...\n",
      "  [76] page 355, para 76: The content of these was a mixture of Greek mythology and festivals and rites de...\n",
      "  [77] page 355, para 77: Under Augustus there was a deliberate attempt to reinvigorate old belief, which ...\n",
      "  [78] page 356, para 78: This was not all that came from the East. By the second century...\n",
      "  [79] page 356, para 79: AD, the distinction of a pure Roman religious tradition from others within the e...\n",
      "  [80] page 356, para 80: All this boils down to a large measure of practical criticism of the ancient Rom...\n",
      "  [81] page 357, para 81: Another symptom of Eastern influence was the popularization of mysteries, cults ...\n",
      "  [82] page 357, para 82: That Roman rule did not satisfy all Roman subjects all the time was even true in...\n",
      "  [83] page 358, para 83: Taxes kept the empire going. Although not heavy in normal times, when they paid ...\n",
      "  [84] page 359, para 84: In the last resort almost everything seems to come back to the army, on which th...\n"
     ]
    }
   ],
   "source": [
    "# Load paragraph data\n",
    "\n",
    "# Option A: 5-paragraph test set\n",
    "# data_path = Path(\"selected_5_paragraphs.json\")\n",
    "# with open(data_path) as f:\n",
    "#     paragraphs = json.load(f)\n",
    "\n",
    "# Option B: Full chapter from database\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent / \"src\"))\n",
    "from history_book.database.config.database_config import WeaviateConfig\n",
    "from history_book.database.repositories.book_repository import BookRepositoryManager\n",
    "config = WeaviateConfig.from_environment()\n",
    "manager = BookRepositoryManager(config)\n",
    "chapter_paragraphs = manager.paragraphs.find_by_chapter_index(book_index=3, chapter_index=4)\n",
    "paragraphs = [\n",
    "    {\"id\": str(p.id), \"text\": p.text, \"page\": p.page, \"paragraph_index\": p.paragraph_index,\n",
    "     \"book_index\": p.book_index, \"chapter_index\": p.chapter_index}\n",
    "    for p in chapter_paragraphs\n",
    "]\n",
    "\n",
    "# Sort by book order so adjacent paragraphs (which share entities) are processed together\n",
    "paragraphs.sort(key=lambda p: (p.get(\"page\", 0), p.get(\"paragraph_index\", 0)))\n",
    "\n",
    "print(f\"Loaded {len(paragraphs)} paragraphs\")\n",
    "for i, p in enumerate(paragraphs):\n",
    "    print(f\"  [{i}] page {p['page']}, para {p['paragraph_index']}: {p['text'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models\n",
    "\n",
    "8 models total:\n",
    "- **Extraction**: `Entity`, `Relationship`, `ExtractionResult` — LLM output shapes\n",
    "- **Post-extraction**: `EntityWithId`, `RelationshipWithId` — UUIDs + bidirectional links\n",
    "- **Normalization**: `NormalizedEntity`, `NormalizedRelationship` — merged duplicates\n",
    "- **LLM merge**: `EntityMergeDecision` — structured merge output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extraction models (LLM output) ---\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    \"\"\"Extracted entity from historical text.\"\"\"\n",
    "    name: str\n",
    "    type: str  # person, place, collective_entity, event, temporal, cultural\n",
    "    subtype: str | None = None\n",
    "    aliases: list[str] = Field(default_factory=list)\n",
    "    description: str | None = None\n",
    "    attributes: dict[str, str] | None = None\n",
    "    confidence: float = Field(default=1.0, ge=0.0, le=1.0)\n",
    "\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    \"\"\"Relationship between two entities.\"\"\"\n",
    "    source_entity: str  # Entity name\n",
    "    relation_type: str\n",
    "    target_entity: str  # Entity name\n",
    "    temporal_context: str | None = None\n",
    "    confidence: float = Field(default=1.0, ge=0.0, le=1.0)\n",
    "\n",
    "\n",
    "class ExtractionResult(BaseModel):\n",
    "    \"\"\"Result of entity extraction from a paragraph.\"\"\"\n",
    "    entities: list[Entity]\n",
    "    relationships: list[Relationship]\n",
    "    paragraph_id: str\n",
    "\n",
    "\n",
    "# --- Post-extraction models (with IDs) ---\n",
    "\n",
    "class EntityWithId(BaseModel):\n",
    "    \"\"\"Entity with UUID assigned after extraction.\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    type: str\n",
    "    subtype: str | None = None\n",
    "    aliases: list[str] = Field(default_factory=list)\n",
    "    description: str | None = None\n",
    "    attributes: dict[str, str] | None = None\n",
    "    confidence: float = Field(default=1.0, ge=0.0, le=1.0)\n",
    "    paragraph_id: str\n",
    "    relationship_ids: list[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "class RelationshipWithId(BaseModel):\n",
    "    \"\"\"Relationship with UUIDs for entities and original names preserved.\"\"\"\n",
    "    id: str\n",
    "    source_id: str  # Entity UUID\n",
    "    target_id: str  # Entity UUID\n",
    "    source_entity_name: str  # Original entity name from extraction\n",
    "    target_entity_name: str  # Original entity name from extraction\n",
    "    relation_type: str\n",
    "    temporal_context: str | None = None\n",
    "    confidence: float = Field(default=1.0, ge=0.0, le=1.0)\n",
    "    paragraph_id: str\n",
    "\n",
    "\n",
    "# --- Normalized models (after merging duplicates) ---\n",
    "\n",
    "class NormalizedEntity(BaseModel):\n",
    "    \"\"\"Normalized entity after merging duplicates.\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    type: str\n",
    "    subtype: str | None = None\n",
    "    aliases: list[str] = Field(default_factory=list)\n",
    "    description: str\n",
    "    attributes: dict[str, str] | None = None\n",
    "    source_paragraph_ids: list[str]\n",
    "    occurrence_count: int\n",
    "    merged_from_ids: list[str] = Field(default_factory=list)\n",
    "    relationship_ids: list[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "class NormalizedRelationship(BaseModel):\n",
    "    \"\"\"Normalized relationship with canonical entity IDs and original names.\"\"\"\n",
    "    id: str\n",
    "    source_id: str  # Normalized entity ID\n",
    "    target_id: str  # Normalized entity ID\n",
    "    source_entity_name: str  # Original entity name from extraction\n",
    "    target_entity_name: str  # Original entity name from extraction\n",
    "    relation_type: str\n",
    "    temporal_context: str | None = None\n",
    "    confidence: float\n",
    "    paragraph_id: str\n",
    "\n",
    "\n",
    "# --- LLM merge decision ---\n",
    "\n",
    "class EntityMergeDecision(BaseModel):\n",
    "    \"\"\"LLM decision on whether two entities should be merged.\"\"\"\n",
    "    reasoning: str = Field(description=\"Brief explanation of the decision\")\n",
    "    confidence: float = Field(ge=0.0, le=1.0, description=\"Confidence in the decision\")\n",
    "    should_merge: bool = Field(description=\"True if entities refer to the same historical entity\")\n",
    "    merged_entity: EntityWithId | None = Field(\n",
    "        default=None,\n",
    "        description=\"The merged entity if should_merge=True, otherwise None\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Extract entities and relationships from each paragraph using structured outputs.\n",
    "The prompt constrains extraction to what's explicitly stated in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACTION_PROMPT = \"\"\"You are analyzing text from \"The Penguin History of the World\".\n",
    "\n",
    "Extract noteworthy entities and relationships from the provided paragraph.\n",
    "\n",
    "**ENTITY TYPES**:\n",
    "- person: Individuals (rulers, leaders, historical figures)\n",
    "- place: Geographic locations (cities, regions, rivers, etc.)\n",
    "- collective_entity: Groups, states, organizations, peoples, leagues\n",
    "- event: Historical events, political actions, battles, reforms\n",
    "- temporal: Time references (centuries, years, dates)\n",
    "- cultural: Cultural concepts, traditions, civilizations\n",
    "\n",
    "**SUBTYPES**:\n",
    "- place: \"city\", \"region\", \"river\", \"sea\"\n",
    "- collective_entity: \"state\", \"people\", \"organization\", \"league\"\n",
    "- temporal: \"century\" (single century), \"year\" (single year), \"date\" (specific date), \"range\" (time range)\n",
    "\n",
    "**RELATIONSHIP TYPES** (examples - extract any you find):\n",
    "- Political: \"ruled\", \"conquered\", \"allied-with\", \"subordinated\", \"revolted-against\", \"succeeded\"\n",
    "- Geographic: \"located-on\", \"located-in\", \"bordered-by\"\n",
    "- Cultural: \"influenced-by\", \"came-from\", \"accessed-through\"\n",
    "- Temporal: \"happened-in\", \"occurred-during\"\n",
    "\n",
    "**IMPORTANT GUIDELINES**:\n",
    "1. Extract entities FROM THIS PARAGRAPH ONLY - do not use external knowledge\n",
    "2. Extract *named* entities only — proper nouns with specific identity (not generic descriptions)\n",
    "3. Extract relationships that are EXPLICITLY STATED in the text\n",
    "4. Include aliases if the entity is referred to by multiple names (e.g., \"Octavian\" also called \"Augustus\")\n",
    "5. For titles/roles, store as attributes\n",
    "6. DO NOT extract:\n",
    "   - Unnamed individuals or groups (\"an astronomer\", \"his great-uncle\", \"money-lenders\")\n",
    "   - Abstract concepts or generic descriptions (\"civil war\", \"Roman power\", \"frontier provinces\")\n",
    "   - Entities mentioned only as comparisons (\"like Athens\")\n",
    "   - Vague references without clear identity\n",
    "7. Include temporal_context in relationships when dates/times are mentioned\n",
    "8. Relationships MUST reference exact entity names from your entities list — do not paraphrase.\n",
    "9. Only extract entities that participate in at least one relationship.\n",
    "\n",
    "Extract entities and relationships from this paragraph:\n",
    "\n",
    "{paragraph_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(paragraph_text: str, paragraph_id: str, config: dict) -> ExtractionResult:\n",
    "    \"\"\"Extract entities and relationships from a paragraph using structured outputs.\"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        model=config[\"extraction_model\"],\n",
    "        temperature=config[\"extraction_temperature\"],\n",
    "    )\n",
    "    llm_with_structure = llm.with_structured_output(ExtractionResult)\n",
    "\n",
    "    system_message = \"You are an expert at extracting structured historical entities and relationships from text.\"\n",
    "    user_message = EXTRACTION_PROMPT.format(paragraph_text=paragraph_text)\n",
    "\n",
    "    result = llm_with_structure.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ])\n",
    "\n",
    "    result.paragraph_id = paragraph_id\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental Pipeline\n",
    "\n",
    "Process paragraphs one at a time into a growing master graph:\n",
    "1. **Extract** entities and relationships from the paragraph\n",
    "2. **Assign IDs** and drop orphans\n",
    "3. **Rule-based merge** into master (exact name + alias matching)\n",
    "4. **Embedding similarity** — compare new entities vs master (not all pairwise)\n",
    "5. **LLM merge** on candidates involving new entities\n",
    "6. **Update master** embeddings and state\n",
    "\n",
    "Key advantage: embedding similarity is `n_new × n_master` per paragraph, not `n_total × n_total`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ids_single(result: ExtractionResult) -> tuple[list[EntityWithId], list[RelationshipWithId]]:\n",
    "    \"\"\"Assign UUIDs to entities and relationships from a single paragraph extraction.\n",
    "    Drops orphaned entities (not referenced by any relationship).\"\"\"\n",
    "    para_entities: dict[str, EntityWithId] = {}\n",
    "    relationships: list[RelationshipWithId] = []\n",
    "    skipped = 0\n",
    "\n",
    "    for entity in result.entities:\n",
    "        entity_id = str(uuid_module.uuid4())\n",
    "        para_entities[entity.name] = EntityWithId(\n",
    "            id=entity_id,\n",
    "            name=entity.name,\n",
    "            type=entity.type,\n",
    "            subtype=entity.subtype,\n",
    "            aliases=entity.aliases,\n",
    "            description=entity.description,\n",
    "            attributes=entity.attributes,\n",
    "            confidence=entity.confidence,\n",
    "            paragraph_id=result.paragraph_id,\n",
    "            relationship_ids=[],\n",
    "        )\n",
    "\n",
    "    for rel in result.relationships:\n",
    "        source = para_entities.get(rel.source_entity)\n",
    "        target = para_entities.get(rel.target_entity)\n",
    "        if source and target:\n",
    "            rel_id = str(uuid_module.uuid4())\n",
    "            rel_with_id = RelationshipWithId(\n",
    "                id=rel_id,\n",
    "                source_id=source.id,\n",
    "                target_id=target.id,\n",
    "                source_entity_name=rel.source_entity,\n",
    "                target_entity_name=rel.target_entity,\n",
    "                relation_type=rel.relation_type,\n",
    "                temporal_context=rel.temporal_context,\n",
    "                confidence=rel.confidence,\n",
    "                paragraph_id=result.paragraph_id,\n",
    "            )\n",
    "            relationships.append(rel_with_id)\n",
    "            source.relationship_ids.append(rel_id)\n",
    "            target.relationship_ids.append(rel_id)\n",
    "        else:\n",
    "            skipped += 1\n",
    "\n",
    "    all_entities = list(para_entities.values())\n",
    "    orphaned = [e for e in all_entities if not e.relationship_ids]\n",
    "    all_entities = [e for e in all_entities if e.relationship_ids]\n",
    "\n",
    "    if skipped:\n",
    "        print(f\"    Skipped {skipped} rels (entity not found)\")\n",
    "    if orphaned:\n",
    "        print(f\"    Dropped {len(orphaned)} orphans: {', '.join(e.name for e in orphaned)}\")\n",
    "\n",
    "    return all_entities, relationships\n",
    "\n",
    "\n",
    "def create_entity_text(entity: NormalizedEntity) -> str:\n",
    "    \"\"\"Create text representation of entity for embedding.\"\"\"\n",
    "    parts = [f\"Name: {entity.name}\", f\"Type: {entity.type}\"]\n",
    "    if entity.subtype:\n",
    "        parts.append(f\"Subtype: {entity.subtype}\")\n",
    "    if entity.description:\n",
    "        parts.append(f\"Description: {entity.description}\")\n",
    "    if entity.aliases:\n",
    "        parts.append(f\"Aliases: {', '.join(entity.aliases)}\")\n",
    "    return \" | \".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_into_master_rule_based(\n",
    "    new_entities: list[EntityWithId],\n",
    "    new_relationships: list[RelationshipWithId],\n",
    "    master_entities: list[NormalizedEntity],\n",
    "    master_relationships: list[NormalizedRelationship],\n",
    ") -> tuple[list[NormalizedEntity], list[NormalizedRelationship], list[NormalizedEntity]]:\n",
    "    \"\"\"\n",
    "    Merge new paragraph entities into master graph using exact name + alias matching.\n",
    "\n",
    "    NOTE: Known limitation — entity names are matched globally without context disambiguation.\n",
    "    For per-chapter processing this is acceptable, but cross-chapter processing may incorrectly\n",
    "    merge entities that share names across different historical contexts (e.g., \"Senate\").\n",
    "\n",
    "    Returns:\n",
    "        (updated_master_entities, updated_master_relationships, newly_added_entities)\n",
    "    \"\"\"\n",
    "    # Build lookup: lowercase name/alias -> master entity\n",
    "    name_to_master: dict[str, NormalizedEntity] = {}\n",
    "    for me in master_entities:\n",
    "        name_to_master[me.name.lower().strip()] = me\n",
    "        for alias in me.aliases:\n",
    "            alias_key = alias.lower().strip()\n",
    "            if alias_key:\n",
    "                name_to_master[alias_key] = me\n",
    "\n",
    "    old_id_to_master_id: dict[str, str] = {}  # new entity ID -> master entity ID\n",
    "    newly_added: list[NormalizedEntity] = []\n",
    "    rule_merges = 0\n",
    "\n",
    "    for entity in new_entities:\n",
    "        key = entity.name.lower().strip()\n",
    "        # Check name and aliases against master\n",
    "        match = name_to_master.get(key)\n",
    "        if not match:\n",
    "            for alias in entity.aliases:\n",
    "                alias_key = alias.lower().strip()\n",
    "                match = name_to_master.get(alias_key)\n",
    "                if match:\n",
    "                    break\n",
    "\n",
    "        if match:\n",
    "            # Merge into existing master entity\n",
    "            rule_merges += 1\n",
    "            print(f\"    Rule merge: '{entity.name}' -> '{match.name}'\")\n",
    "            match.aliases = list(set(match.aliases + entity.aliases + [entity.name]))\n",
    "            # Remove self-referencing aliases\n",
    "            match.aliases = [a for a in match.aliases if a.lower().strip() != match.name.lower().strip()]\n",
    "            if entity.description:\n",
    "                match.description = f\"{match.description} | {entity.description}\" if match.description else entity.description\n",
    "            if entity.attributes:\n",
    "                match.attributes = {**(match.attributes or {}), **entity.attributes}\n",
    "            match.source_paragraph_ids = list(set(match.source_paragraph_ids + [entity.paragraph_id]))\n",
    "            match.occurrence_count += 1\n",
    "            match.merged_from_ids.append(entity.id)\n",
    "            old_id_to_master_id[entity.id] = match.id\n",
    "            # Update lookup with new aliases\n",
    "            for alias in entity.aliases:\n",
    "                alias_key = alias.lower().strip()\n",
    "                if alias_key:\n",
    "                    name_to_master[alias_key] = match\n",
    "        else:\n",
    "            # Create new master entity\n",
    "            new_master = NormalizedEntity(\n",
    "                id=str(uuid_module.uuid4()),\n",
    "                name=entity.name,\n",
    "                type=entity.type,\n",
    "                subtype=entity.subtype,\n",
    "                aliases=entity.aliases,\n",
    "                description=entity.description or \"\",\n",
    "                attributes=entity.attributes,\n",
    "                source_paragraph_ids=[entity.paragraph_id],\n",
    "                occurrence_count=1,\n",
    "                merged_from_ids=[entity.id],\n",
    "                relationship_ids=[],\n",
    "            )\n",
    "            master_entities.append(new_master)\n",
    "            newly_added.append(new_master)\n",
    "            old_id_to_master_id[entity.id] = new_master.id\n",
    "            # Update lookup\n",
    "            name_to_master[key] = new_master\n",
    "            for alias in entity.aliases:\n",
    "                alias_key = alias.lower().strip()\n",
    "                if alias_key:\n",
    "                    name_to_master[alias_key] = new_master\n",
    "\n",
    "    # Remap relationships to master IDs\n",
    "    master_entity_lookup = {e.id: e for e in master_entities}\n",
    "    for rel in new_relationships:\n",
    "        new_source = old_id_to_master_id.get(rel.source_id)\n",
    "        new_target = old_id_to_master_id.get(rel.target_id)\n",
    "        if new_source and new_target:\n",
    "            norm_rel = NormalizedRelationship(\n",
    "                id=rel.id,\n",
    "                source_id=new_source,\n",
    "                target_id=new_target,\n",
    "                source_entity_name=rel.source_entity_name,\n",
    "                target_entity_name=rel.target_entity_name,\n",
    "                relation_type=rel.relation_type,\n",
    "                temporal_context=rel.temporal_context,\n",
    "                confidence=rel.confidence,\n",
    "                paragraph_id=rel.paragraph_id,\n",
    "            )\n",
    "            master_relationships.append(norm_rel)\n",
    "            if new_source in master_entity_lookup:\n",
    "                master_entity_lookup[new_source].relationship_ids.append(rel.id)\n",
    "            if new_target in master_entity_lookup:\n",
    "                master_entity_lookup[new_target].relationship_ids.append(rel.id)\n",
    "\n",
    "    if rule_merges:\n",
    "        print(f\"    {rule_merges} rule-based merge(s)\")\n",
    "\n",
    "    return master_entities, master_relationships, newly_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_candidates_against_master(\n",
    "    new_entities: list[NormalizedEntity],\n",
    "    new_embeddings: np.ndarray,\n",
    "    master_entities: list[NormalizedEntity],\n",
    "    master_embeddings: np.ndarray,\n",
    "    threshold: float,\n",
    ") -> list[dict]:\n",
    "    \"\"\"Find merge candidates: new entities vs existing master entities.\n",
    "    Returns pairs sorted by descending similarity.\"\"\"\n",
    "    if len(new_embeddings) == 0 or len(master_embeddings) == 0:\n",
    "        return []\n",
    "\n",
    "    # (n_new, n_master) — NOT all pairwise\n",
    "    sim_matrix = cosine_similarity(new_embeddings, master_embeddings)\n",
    "\n",
    "    candidates = []\n",
    "    for i in range(len(new_entities)):\n",
    "        for j in range(len(master_entities)):\n",
    "            sim = sim_matrix[i, j]\n",
    "            if sim >= threshold:\n",
    "                candidates.append({\n",
    "                    \"new_entity\": new_entities[i],\n",
    "                    \"master_entity\": master_entities[j],\n",
    "                    \"similarity\": float(sim),\n",
    "                })\n",
    "\n",
    "    candidates.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def levenshtein_similarity(s1: str, s2: str) -> float:\n",
    "    \"\"\"Normalized Levenshtein similarity in [0,1], case-insensitive.\n",
    "    1.0 = identical, 0.0 = completely different.\"\"\"\n",
    "    s1, s2 = s1.lower().strip(), s2.lower().strip()\n",
    "    if s1 == s2:\n",
    "        return 1.0\n",
    "    if not s1 or not s2:\n",
    "        return 0.0\n",
    "    m, n = len(s1), len(s2)\n",
    "    dp = list(range(n + 1))\n",
    "    for i in range(1, m + 1):\n",
    "        prev = dp[0]\n",
    "        dp[0] = i\n",
    "        for j in range(1, n + 1):\n",
    "            temp = dp[j]\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                dp[j] = prev\n",
    "            else:\n",
    "                dp[j] = 1 + min(prev, dp[j], dp[j - 1])\n",
    "            prev = temp\n",
    "    return 1.0 - dp[n] / max(m, n)\n",
    "\n",
    "\n",
    "def find_candidates_levenshtein(\n",
    "    new_entities: list[NormalizedEntity],\n",
    "    master_entities: list[NormalizedEntity],\n",
    "    threshold: float,\n",
    ") -> list[dict]:\n",
    "    \"\"\"Find merge candidates using Levenshtein similarity on names + aliases.\n",
    "    For each (new, master) pair, compares all name+alias combinations and takes the best score.\n",
    "    Returns same format as cosine version, sorted by descending similarity.\"\"\"\n",
    "    candidates = []\n",
    "    for ne in new_entities:\n",
    "        ne_names = [ne.name] + ne.aliases\n",
    "        for me in master_entities:\n",
    "            me_names = [me.name] + me.aliases\n",
    "            best = 0.0\n",
    "            for n1 in ne_names:\n",
    "                for n2 in me_names:\n",
    "                    s = levenshtein_similarity(n1, n2)\n",
    "                    if s > best:\n",
    "                        best = s\n",
    "            if best >= threshold:\n",
    "                candidates.append({\n",
    "                    \"new_entity\": ne,\n",
    "                    \"master_entity\": me,\n",
    "                    \"similarity\": best,\n",
    "                })\n",
    "    candidates.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM merge prompt — used for ambiguous candidates that pass embedding similarity threshold\n",
    "\n",
    "ENTITY_MERGE_PROMPT = \"\"\"You are an expert historian analyzing entity mentions from \"The Penguin History of the World\".\n",
    "\n",
    "Given two entities extracted from different paragraphs, determine if they refer to the SAME historical entity.\n",
    "This is an entity normalization task as part of knowledge graph construction. The goal is to merge duplicate entities while maintaining distinct but related entities separately.\n",
    "\n",
    "**Entity 1:**\n",
    "Name: {entity1_name}\n",
    "Type: {entity1_type}\n",
    "Subtype: {entity1_subtype}\n",
    "Aliases: {entity1_aliases}\n",
    "Description: {entity1_description}\n",
    "Attributes: {entity1_attributes}\n",
    "\n",
    "**Entity 2:**\n",
    "Name: {entity2_name}\n",
    "Type: {entity2_type}\n",
    "Subtype: {entity2_subtype}\n",
    "Aliases: {entity2_aliases}\n",
    "Description: {entity2_description}\n",
    "Attributes: {entity2_attributes}\n",
    "\n",
    "**Instructions:**\n",
    "1. Determine if these refer to the SAME historical entity (person, place, organization, etc.)\n",
    "    - Same here means strictly identical entities, not just similar or related.\n",
    "    - mergeable examples:\n",
    "        - \"Octavian\" and \"Augustus\" (same person, different names)\n",
    "        - \"Roman Legions\" and \"Roman Army\" (same organization)\n",
    "        - \"Roman Republic\" and \"Rome\" (same political entity)\n",
    "    - non-mergeable examples:\n",
    "        - Different people with same last name (e.g., \"Julius Caesar\" vs \"Augustus Caesar\")\n",
    "        - Same place in different contexts (e.g., \"Rome\" the city vs \"Rome\" the empire)\n",
    "        - Related political and geographical entities (e.g., \"Roman Empire\" vs \"Italy\")\n",
    "        - Different entity types (e.g., \"Etruscan dominion\" vs \"509 BC\")\n",
    "2. If they should be merged:\n",
    "   - Choose the most canonical/common name\n",
    "   - Write a consolidated description (combine key information, ~2-3 sentences)\n",
    "   - Merge aliases (include both original names if not already aliases)\n",
    "   - Combine attributes (later values override if conflict)\n",
    "   - Set confidence as average of both entities\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_merge_chain(config: dict):\n",
    "    \"\"\"Create LangChain chain for entity merge decisions.\"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        model=config[\"merge_model\"],\n",
    "        temperature=config[\"merge_temperature\"],\n",
    "        reasoning_effort=config.get(\"reasoning_effort\", None),\n",
    "    )\n",
    "    llm_with_structure = llm.with_structured_output(EntityMergeDecision)\n",
    "    prompt = ChatPromptTemplate.from_template(ENTITY_MERGE_PROMPT)\n",
    "    return prompt | llm_with_structure\n",
    "\n",
    "\n",
    "def format_entity_for_prompt(entity) -> dict:\n",
    "    \"\"\"Format an entity (EntityWithId or NormalizedEntity) for the merge prompt.\"\"\"\n",
    "    aliases = entity.aliases if entity.aliases else []\n",
    "    return {\n",
    "        \"name\": entity.name,\n",
    "        \"type\": entity.type,\n",
    "        \"subtype\": entity.subtype or \"None\",\n",
    "        \"aliases\": \", \".join(aliases) if aliases else \"None\",\n",
    "        \"description\": entity.description or \"None\",\n",
    "        \"attributes\": str(entity.attributes) if entity.attributes else \"None\",\n",
    "    }\n",
    "\n",
    "\n",
    "def decide_entity_merge(entity1, entity2, chain) -> EntityMergeDecision:\n",
    "    \"\"\"Run the merge decision chain on two entities.\"\"\"\n",
    "    e1 = format_entity_for_prompt(entity1)\n",
    "    e2 = format_entity_for_prompt(entity2)\n",
    "    inputs = {}\n",
    "    for key, val in e1.items():\n",
    "        inputs[f\"entity1_{key}\"] = val\n",
    "    for key, val in e2.items():\n",
    "        inputs[f\"entity2_{key}\"] = val\n",
    "    return chain.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate finding: levenshtein (threshold: 0.6)\n",
      "Tracking both cosine and levenshtein similarity for all candidates\n",
      "\n",
      "    Skipped 5 rels (entity not found)\n",
      "[0] p317 para 0 | +4 ext, 4 kept | rule: 0 merged, 4 new | llm: 0 cand, 0 checked, 0 merged | master: 4e 2r\n",
      "[1] p318 para 1 | 0 entities after filtering\n",
      "    Rule merge: 'Rome' -> 'Rome'\n",
      "    1 rule-based merge(s)\n",
      "[2] p318 para 2 | +4 ext, 4 kept | rule: 1 merged, 3 new | llm: 0 cand, 0 checked, 0 merged | master: 7e 5r\n",
      "    Dropped 1 orphans: Hittite empire\n",
      "    Rule merge: 'Etruscans' -> 'Etruscans'\n",
      "    1 rule-based merge(s)\n",
      "[3] p318 para 3 | +7 ext, 6 kept | rule: 1 merged, 5 new | llm: 1 cand, 1 checked, 0 merged | master: 12e 9r\n",
      "    Skipped 10 rels (entity not found)\n",
      "    Dropped 10 orphans: Indo-European invaders, Italians, Villanovan culture, Bologna, Elba, Etruria, Po valley, Campania, Magna Graecia, 1000 BC\n",
      "    Rule merge: 'Etruscans' -> 'Etruscans'\n",
      "    1 rule-based merge(s)\n",
      "[4] p318 para 4 | +12 ext, 2 kept | rule: 1 merged, 1 new | llm: 0 cand, 0 checked, 0 merged | master: 13e 10r\n",
      "    Skipped 3 rels (entity not found)\n",
      "    Dropped 1 orphans: western Greeks\n",
      "    Rule merge: 'Etruscans' -> 'Etruscans'\n",
      "    Rule merge: 'Rome' -> 'Rome'\n",
      "    Rule merge: 'Greek civilization' -> 'Greek civilization'\n",
      "    3 rule-based merge(s)\n",
      "[5] p319 para 5 | +9 ext, 8 kept | rule: 3 merged, 5 new | llm: 0 cand, 0 checked, 0 merged | master: 18e 20r\n",
      "    Rule merge: 'Rome' -> 'Rome'\n",
      "    1 rule-based merge(s)\n",
      "  ** LLM MERGE: Etruscan + Etruscans (cos:0.825, lev:0.889)\n",
      "[6] p321 para 6 | +3 ext, 3 kept | rule: 1 merged, 2 new | llm: 2 cand, 2 checked, 1 merged | master: 20e 22r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 2 orphans: Great Britain, United States\n",
      "    Rule merge: 'Rome' -> 'Rome'\n",
      "    Rule merge: 'Roman empire' -> 'Roman Empire'\n",
      "    Rule merge: 'Europe' -> 'Europe'\n",
      "    3 rule-based merge(s)\n",
      "[7] p321 para 7 | +10 ext, 8 kept | rule: 3 merged, 5 new | llm: 1 cand, 1 checked, 0 merged | master: 25e 29r\n",
      "[8] p321 para 8 | 0 entities after filtering\n",
      "    Skipped 3 rels (entity not found)\n",
      "    Rule merge: 'Rome' -> 'Rome'\n",
      "    1 rule-based merge(s)\n",
      "[9] p322 para 9 | +5 ext, 5 kept | rule: 1 merged, 4 new | llm: 2 cand, 2 checked, 0 merged | master: 29e 35r\n",
      "    Skipped 7 rels (entity not found)\n",
      "    Dropped 6 orphans: early republic, citizen body, 300 BC, old patricians, plebs, census\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    1 rule-based merge(s)\n",
      "[10] p322 para 10 | +9 ext, 3 kept | rule: 1 merged, 2 new | llm: 0 cand, 0 checked, 0 merged | master: 31e 37r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 1 orphans: sixth century BC\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    1 rule-based merge(s)\n",
      "  ** LLM MERGE: consuls + consul (cos:0.595, lev:0.857)\n",
      "[11] p322 para 11 | +10 ext, 9 kept | rule: 1 merged, 8 new | llm: 1 cand, 1 checked, 1 merged | master: 39e 46r\n",
      "    Skipped 4 rels (entity not found)\n",
      "    Dropped 3 orphans: Latin, pecunia, Rome\n",
      "    Rule merge: 'Plebs' -> 'plebs'\n",
      "    1 rule-based merge(s)\n",
      "[12] p323 para 12 | +6 ext, 3 kept | rule: 1 merged, 2 new | llm: 1 cand, 1 checked, 0 merged | master: 41e 48r\n",
      "    Dropped 1 orphans: slaves\n",
      "    Rule merge: 'Etruscan' -> 'Etruscan'\n",
      "    1 rule-based merge(s)\n",
      "  ** LLM MERGE: early republic + Roman republic (cos:0.768, lev:0.643)\n",
      "[13] p323 para 13 | +5 ext, 4 kept | rule: 1 merged, 3 new | llm: 2 cand, 2 checked, 1 merged | master: 44e 52r\n",
      "    Skipped 6 rels (entity not found)\n",
      "    Dropped 5 orphans: Rome, plebs, aristocracy, third century BC, second century BC\n",
      "[14] p324 para 14 | 0 entities after filtering\n",
      "    Dropped 3 orphans: Italy, 366 BC, 287 BC\n",
      "    Rule merge: 'Rome' -> 'Rome'\n",
      "    Rule merge: 'plebs' -> 'plebs'\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    Rule merge: 'consuls' -> 'consuls'\n",
      "    4 rule-based merge(s)\n",
      "[15] p324 para 15 | +9 ext, 6 kept | rule: 4 merged, 2 new | llm: 0 cand, 0 checked, 0 merged | master: 46e 58r\n",
      "    Skipped 4 rels (entity not found)\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    Rule merge: 'consuls' -> 'consuls'\n",
      "    2 rule-based merge(s)\n",
      "[16] p324 para 16 | +3 ext, 3 kept | rule: 2 merged, 1 new | llm: 0 cand, 0 checked, 0 merged | master: 47e 62r\n",
      "    Skipped 13 rels (entity not found)\n",
      "    Dropped 5 orphans: Thebes, Syracuse, Rome, Latin League, middle of the fourth century BC\n",
      "    Rule merge: 'Roman Republic' -> 'Roman republic'\n",
      "    1 rule-based merge(s)\n",
      "[17] p325 para 17 | +8 ext, 3 kept | rule: 1 merged, 2 new | llm: 3 cand, 3 checked, 0 merged | master: 49e 64r\n",
      "    Rule merge: 'Etruscan' -> 'Etruscan'\n",
      "    1 rule-based merge(s)\n",
      "  ** LLM MERGE: Roman + Romans (cos:0.752, lev:0.833)\n",
      "[18] p326 para 18 | +3 ext, 3 kept | rule: 1 merged, 2 new | llm: 2 cand, 2 checked, 1 merged | master: 51e 66r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 1 orphans: fourth century BC\n",
      "    Rule merge: 'Roman Republic' -> 'Roman republic'\n",
      "    Rule merge: 'Rome' -> 'Rome'\n",
      "    Rule merge: 'central Italy' -> 'central Italy'\n",
      "    3 rule-based merge(s)\n",
      "[19] p326 para 19 | +8 ext, 7 kept | rule: 3 merged, 4 new | llm: 1 cand, 1 checked, 0 merged | master: 55e 71r\n",
      "    Dropped 1 orphans: 280–275 BC\n",
      "    Rule merge: 'Rome' -> 'Rome'\n",
      "    Rule merge: 'Romans' -> 'Romans'\n",
      "    2 rule-based merge(s)\n",
      "[20] p326 para 20 | +10 ext, 9 kept | rule: 2 merged, 7 new | llm: 1 cand, 1 checked, 0 merged | master: 62e 79r\n",
      "    Dropped 1 orphans: 264–241 BC\n",
      "    Rule merge: 'Romans' -> 'Romans'\n",
      "    Rule merge: 'Syracuse' -> 'Syracuse'\n",
      "    2 rule-based merge(s)\n",
      "[21] p326 para 21 | +7 ext, 6 kept | rule: 2 merged, 4 new | llm: 0 cand, 0 checked, 0 merged | master: 66e 84r\n",
      "    Dropped 1 orphans: 227 BC\n",
      "    Rule merge: 'Sardinia' -> 'Sardinia'\n",
      "    1 rule-based merge(s)\n",
      "[22] p327 para 22 | +5 ext, 4 kept | rule: 1 merged, 3 new | llm: 1 cand, 1 checked, 0 merged | master: 69e 87r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 1 orphans: Second Punic War\n",
      "    Rule merge: 'Carthaginians' -> 'Carthaginians'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Italy' -> 'Italy'\n",
      "    Rule merge: 'Central Italy' -> 'central Italy'\n",
      "    4 rule-based merge(s)\n",
      "  ** LLM MERGE: Greek cities + western Greek cities (cos:0.765, lev:0.600)\n",
      "[23] p327 para 23 | +12 ext, 11 kept | rule: 4 merged, 7 new | llm: 2 cand, 2 checked, 1 merged | master: 76e 97r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 3 orphans: 209 BC, 207 BC, 202 BC\n",
      "    Rule merge: 'Hannibal' -> 'Hannibal'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Carthage' -> 'Carthage'\n",
      "    Rule merge: 'Spain' -> 'Spain'\n",
      "    4 rule-based merge(s)\n",
      "[24] p327 para 24 | +12 ext, 9 kept | rule: 4 merged, 5 new | llm: 2 cand, 2 checked, 0 merged | master: 81e 108r\n",
      "    Rule merge: 'Italy' -> 'Italy'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Carthage' -> 'Carthage'\n",
      "    Rule merge: 'Hannibal' -> 'Hannibal'\n",
      "    Rule merge: 'Syracuse' -> 'Syracuse'\n",
      "    Rule merge: 'Sicily' -> 'Sicily'\n",
      "    6 rule-based merge(s)\n",
      "[25] p328 para 25 | +9 ext, 9 kept | rule: 6 merged, 3 new | llm: 0 cand, 0 checked, 0 merged | master: 84e 117r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 2 orphans: Greek Isthmian games, Pergamon\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Carthage' -> 'Carthage'\n",
      "    Rule merge: 'Greek cities' -> 'Greek cities'\n",
      "    3 rule-based merge(s)\n",
      "[26] p328 para 26 | +11 ext, 9 kept | rule: 3 merged, 6 new | llm: 0 cand, 0 checked, 0 merged | master: 90e 126r\n",
      "    Dropped 1 orphans: Zama\n",
      "    Rule merge: 'Roman' -> 'Roman'\n",
      "    Rule merge: 'Carthage' -> 'Carthage'\n",
      "    Rule merge: 'Sardinia' -> 'Sardinia'\n",
      "    Rule merge: 'Spain' -> 'Spain'\n",
      "    Rule merge: 'Sicily' -> 'Sicily'\n",
      "    5 rule-based merge(s)\n",
      "[27] p329 para 27 | +7 ext, 6 kept | rule: 5 merged, 1 new | llm: 0 cand, 0 checked, 0 merged | master: 91e 135r\n",
      "    Skipped 11 rels (entity not found)\n",
      "    Dropped 17 orphans: Roman expansion in the east, 148 BC, Greece, Syrian king, Asia Minor, kingdom of Pergamon, Aegean, province of Asia, 133 BC, Spain, Illyria, southern France, 121 BC, Gibraltar, Thessaly, 149 BC, western Tunisia\n",
      "    Rule merge: 'Macedon' -> 'Macedon'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Carthage' -> 'Carthage'\n",
      "    Rule merge: 'Africa' -> 'Africa'\n",
      "    4 rule-based merge(s)\n",
      "[28] p329 para 28 | +22 ext, 5 kept | rule: 4 merged, 1 new | llm: 1 cand, 1 checked, 0 merged | master: 92e 139r\n",
      "    Skipped 4 rels (entity not found)\n",
      "    Dropped 1 orphans: legions\n",
      "    Rule merge: 'Roman empire' -> 'Roman Empire'\n",
      "    Rule merge: 'republic' -> 'Roman republic'\n",
      "    2 rule-based merge(s)\n",
      "  ** LLM MERGE: Carthaginian + Carthaginians (cos:0.862, lev:0.923)\n",
      "  ** LLM MERGE: provinces + Roman provinces (cos:0.848, lev:0.600)\n",
      "[29] p330 para 29 | +10 ext, 9 kept | rule: 2 merged, 7 new | llm: 4 cand, 4 checked, 2 merged | master: 99e 145r\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    1 rule-based merge(s)\n",
      "  ** LLM MERGE: governors + governor (cos:0.668, lev:0.889)\n",
      "  ** LLM MERGE: new provinces + Roman provinces (cos:0.708, lev:0.692)\n",
      "[30] p330 para 30 | +9 ext, 9 kept | rule: 1 merged, 8 new | llm: 4 cand, 3 checked, 2 merged | master: 107e 152r\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    1 rule-based merge(s)\n",
      "[31] p331 para 31 | +3 ext, 3 kept | rule: 1 merged, 2 new | llm: 3 cand, 3 checked, 0 merged | master: 109e 154r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 2 orphans: Greeks, Archimedes\n",
      "    Rule merge: 'Italy' -> 'Italy'\n",
      "    Rule merge: 'Greek cities' -> 'Greek cities'\n",
      "    Rule merge: 'Macedon' -> 'Macedon'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Carthage' -> 'Carthage'\n",
      "    Rule merge: 'Syracuse' -> 'Syracuse'\n",
      "    6 rule-based merge(s)\n",
      "[32] p331 para 32 | +10 ext, 8 kept | rule: 6 merged, 2 new | llm: 2 cand, 2 checked, 0 merged | master: 111e 160r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 1 orphans: Alexander\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Greek cities' -> 'Greek cities'\n",
      "    Rule merge: 'Carthage' -> 'Carthage'\n",
      "    3 rule-based merge(s)\n",
      "[33] p332 para 33 | +7 ext, 6 kept | rule: 3 merged, 3 new | llm: 0 cand, 0 checked, 0 merged | master: 114e 168r\n",
      "    Skipped 6 rels (entity not found)\n",
      "    Dropped 4 orphans: Mediterranean, Roman administration, 450 BC, Twelve Tables\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Roman republic' -> 'Roman republic'\n",
      "    2 rule-based merge(s)\n",
      "[34] p332 para 34 | +7 ext, 3 kept | rule: 2 merged, 1 new | llm: 0 cand, 0 checked, 0 merged | master: 115e 170r\n",
      "    Dropped 1 orphans: Middle East\n",
      "    Rule merge: 'Cisalpine Gaul' -> 'Po valley'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Asia' -> 'Asia'\n",
      "    3 rule-based merge(s)\n",
      "[35] p333 para 35 | +13 ext, 12 kept | rule: 3 merged, 9 new | llm: 3 cand, 3 checked, 0 merged | master: 124e 181r\n",
      "    Skipped 9 rels (entity not found)\n",
      "    Dropped 7 orphans: Italian peasant, second Punic War, southern Italy, imperial enterprise, Roman citizen, Rome, Rome’s allies\n",
      "[36] p333 para 36 | +14 ext, 7 kept | rule: 0 merged, 7 new | llm: 0 cand, 0 checked, 0 merged | master: 131e 186r\n",
      "    Skipped 4 rels (entity not found)\n",
      "    Dropped 2 orphans: Roman pool of manpower, 107 BC\n",
      "    Rule merge: 'Roman army' -> 'Roman army'\n",
      "    Rule merge: 'Punic Wars' -> 'Punic Wars'\n",
      "    2 rule-based merge(s)\n",
      "[37] p334 para 37 | +6 ext, 4 kept | rule: 2 merged, 2 new | llm: 0 cand, 0 checked, 0 merged | master: 133e 189r\n",
      "    Skipped 5 rels (entity not found)\n",
      "    Dropped 3 orphans: central Italy, second century BC, Roman republic\n",
      "    Rule merge: 'Tribunes of the People' -> 'Tribunes of the People'\n",
      "    Rule merge: 'plebs' -> 'plebs'\n",
      "    2 rule-based merge(s)\n",
      "[38] p335 para 38 | +7 ext, 4 kept | rule: 2 merged, 2 new | llm: 0 cand, 0 checked, 0 merged | master: 135e 192r\n",
      "    Skipped 8 rels (entity not found)\n",
      "    Dropped 6 orphans: 112 BC, Latin states, Italian states, Italy, 82 BC, Roman Senate\n",
      "    Rule merge: 'Gaul' -> 'Gaul'\n",
      "    Rule merge: 'Marius' -> 'Marius'\n",
      "    Rule merge: 'Roman republic' -> 'Roman republic'\n",
      "    Rule merge: 'socii' -> 'allies'\n",
      "    4 rule-based merge(s)\n",
      "[39] p336 para 39 | +18 ext, 12 kept | rule: 4 merged, 8 new | llm: 0 cand, 0 checked, 0 merged | master: 143e 203r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 1 orphans: 70 BC\n",
      "    Rule merge: 'Sulla' -> 'Sulla'\n",
      "    Rule merge: 'Pontus' -> 'Pontus'\n",
      "    2 rule-based merge(s)\n",
      "[40] p336 para 40 | +5 ext, 4 kept | rule: 2 merged, 2 new | llm: 2 cand, 2 checked, 0 merged | master: 145e 206r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 1 orphans: Rome\n",
      "    Rule merge: 'Pompey' -> 'Pompey'\n",
      "    Rule merge: 'Gaul' -> 'Gaul'\n",
      "    2 rule-based merge(s)\n",
      "[41] p337 para 41 | +6 ext, 5 kept | rule: 2 merged, 3 new | llm: 0 cand, 0 checked, 0 merged | master: 148e 211r\n",
      "    Dropped 1 orphans: January 49 BC\n",
      "    Rule merge: 'Caesar' -> 'Julius Caesar'\n",
      "    Rule merge: 'Gaul' -> 'Gaul'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    3 rule-based merge(s)\n",
      "[42] p337 para 42 | +5 ext, 4 kept | rule: 3 merged, 1 new | llm: 0 cand, 0 checked, 0 merged | master: 149e 215r\n",
      "    Skipped 3 rels (entity not found)\n",
      "    Dropped 2 orphans: Rubicon, 45 BC\n",
      "    Rule merge: 'Pompey' -> 'Pompey'\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    Rule merge: 'Caesar' -> 'Julius Caesar'\n",
      "    Rule merge: 'Spain' -> 'Spain'\n",
      "    Rule merge: 'Egypt' -> 'Egypt'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Africa' -> 'Africa'\n",
      "    7 rule-based merge(s)\n",
      "[43] p338 para 43 | +12 ext, 10 kept | rule: 7 merged, 3 new | llm: 0 cand, 0 checked, 0 merged | master: 152e 228r\n",
      "    Skipped 3 rels (entity not found)\n",
      "    Rule merge: 'Caesar' -> 'Julius Caesar'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    3 rule-based merge(s)\n",
      "[44] p339 para 44 | +7 ext, 7 kept | rule: 3 merged, 4 new | llm: 2 cand, 2 checked, 0 merged | master: 156e 234r\n",
      "    Dropped 1 orphans: 15 March 44 BC\n",
      "    Rule merge: 'Caesar' -> 'Julius Caesar'\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    2 rule-based merge(s)\n",
      "[45] p340 para 45 | +4 ext, 3 kept | rule: 2 merged, 1 new | llm: 1 cand, 1 checked, 0 merged | master: 157e 236r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 1 orphans: Julius Caesar\n",
      "    Rule merge: 'The republic' -> 'Roman republic'\n",
      "    Rule merge: 'Italy' -> 'Italy'\n",
      "    2 rule-based merge(s)\n",
      "[46] p340 para 46 | +4 ext, 3 kept | rule: 2 merged, 1 new | llm: 0 cand, 0 checked, 0 merged | master: 158e 240r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 2 orphans: Greek, Alexander\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Julius Caesar' -> 'Julius Caesar'\n",
      "    2 rule-based merge(s)\n",
      "[47] p340 para 47 | +6 ext, 4 kept | rule: 2 merged, 2 new | llm: 0 cand, 0 checked, 0 merged | master: 160e 243r\n",
      "    Skipped 3 rels (entity not found)\n",
      "    Dropped 1 orphans: Ptolemies\n",
      "    Rule merge: 'Octavian' -> 'Octavian'\n",
      "    Rule merge: 'Julius Caesar' -> 'Julius Caesar'\n",
      "    Rule merge: 'Cleopatra' -> 'Cleopatra'\n",
      "    Rule merge: 'Egypt' -> 'Egypt'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    5 rule-based merge(s)\n",
      "[48] p341 para 48 | +8 ext, 7 kept | rule: 5 merged, 2 new | llm: 0 cand, 0 checked, 0 merged | master: 162e 250r\n",
      "    Skipped 3 rels (entity not found)\n",
      "    Dropped 1 orphans: 27 BC\n",
      "    Rule merge: 'Octavian' -> 'Octavian'\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    3 rule-based merge(s)\n",
      "[49] p341 para 49 | +5 ext, 4 kept | rule: 3 merged, 1 new | llm: 2 cand, 2 checked, 0 merged | master: 163e 253r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 2 orphans: 23 BC, 12 BC\n",
      "    Rule merge: 'Augustus' -> 'Octavian'\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    Rule merge: 'provinces' -> 'provinces'\n",
      "    Rule merge: 'consuls' -> 'consuls'\n",
      "    4 rule-based merge(s)\n",
      "[50] p342 para 50 | +8 ext, 6 kept | rule: 4 merged, 2 new | llm: 0 cand, 0 checked, 0 merged | master: 165e 260r\n",
      "    Skipped 7 rels (entity not found)\n",
      "    Dropped 4 orphans: Caesars, Augustan benevolent despotism, Augustan age, Roman architects and engineers\n",
      "    Rule merge: 'Black Sea' -> 'Black Sea'\n",
      "    Rule merge: 'Augustus' -> 'Octavian'\n",
      "    Rule merge: 'Julius Caesar' -> 'Julius Caesar'\n",
      "    3 rule-based merge(s)\n",
      "[51] p342 para 51 | +8 ext, 4 kept | rule: 3 merged, 1 new | llm: 0 cand, 0 checked, 0 merged | master: 166e 262r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 1 orphans: Rome\n",
      "    Rule merge: 'Augustus' -> 'Octavian'\n",
      "    1 rule-based merge(s)\n",
      "[52] p343 para 52 | +4 ext, 3 kept | rule: 1 merged, 2 new | llm: 1 cand, 1 checked, 0 merged | master: 168e 265r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 1 orphans: Senate\n",
      "    Rule merge: 'Tiberius' -> 'Tiberius'\n",
      "    Rule merge: 'Augustus' -> 'Octavian'\n",
      "    2 rule-based merge(s)\n",
      "[53] p343 para 53 | +6 ext, 5 kept | rule: 2 merged, 3 new | llm: 0 cand, 0 checked, 0 merged | master: 171e 268r\n",
      "    Skipped 7 rels (entity not found)\n",
      "    Dropped 2 orphans: Vespasian, Augustus\n",
      "[54] p344 para 54 | +10 ext, 8 kept | rule: 0 merged, 8 new | llm: 1 cand, 1 checked, 0 merged | master: 179e 274r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 2 orphans: Elbe, AD 9\n",
      "    Rule merge: 'Augustus' -> 'Octavian'\n",
      "    Rule merge: 'Julius Caesar' -> 'Julius Caesar'\n",
      "    Rule merge: 'Gaul' -> 'Gaul'\n",
      "    Rule merge: 'Roman legions' -> 'legions'\n",
      "    4 rule-based merge(s)\n",
      "[55] p344 para 55 | +13 ext, 11 kept | rule: 4 merged, 7 new | llm: 0 cand, 0 checked, 0 merged | master: 186e 285r\n",
      "    Skipped 4 rels (entity not found)\n",
      "    Dropped 5 orphans: Mauretania, Asia, AD 43, AD 42, AD 105\n",
      "    Rule merge: 'Britain' -> 'Britain'\n",
      "    Rule merge: 'Trajan' -> 'Trajan'\n",
      "    2 rule-based merge(s)\n",
      "[56] p345 para 56 | +12 ext, 7 kept | rule: 2 merged, 5 new | llm: 9 cand, 9 checked, 0 merged | master: 191e 290r\n",
      "    Skipped 11 rels (entity not found)\n",
      "    Dropped 3 orphans: Armenia, Pompey, Chinese\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Sulla' -> 'Sulla'\n",
      "    2 rule-based merge(s)\n",
      "[57] p345 para 57 | +8 ext, 5 kept | rule: 2 merged, 3 new | llm: 2 cand, 2 checked, 0 merged | master: 194e 296r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 2 orphans: Rome, Parthia\n",
      "    Rule merge: 'Euphrates' -> 'Euphrates'\n",
      "    Rule merge: 'Parthians' -> 'Parthians'\n",
      "    Rule merge: 'Mark Antony' -> 'Mark Antony'\n",
      "    3 rule-based merge(s)\n",
      "[58] p345 para 58 | +8 ext, 6 kept | rule: 3 merged, 3 new | llm: 2 cand, 2 checked, 0 merged | master: 197e 301r\n",
      "    Dropped 1 orphans: Parthian capital\n",
      "    Rule merge: 'Augustus' -> 'Octavian'\n",
      "    Rule merge: 'Crassus' -> 'Crassus'\n",
      "    Rule merge: 'Parthia' -> 'Parthia'\n",
      "    Rule merge: 'Armenia' -> 'Armenia'\n",
      "    Rule merge: 'Trajan' -> 'Trajan'\n",
      "    Rule merge: 'Hadrian' -> 'Hadrian'\n",
      "    6 rule-based merge(s)\n",
      "[59] p346 para 59 | +10 ext, 9 kept | rule: 6 merged, 3 new | llm: 1 cand, 1 checked, 0 merged | master: 200e 310r\n",
      "    Skipped 4 rels (entity not found)\n",
      "    Dropped 3 orphans: Caesar, Gaul, first century AD\n",
      "    Rule merge: 'Roman' -> 'Roman'\n",
      "    Rule merge: 'Pax Romana' -> 'Pax Romana'\n",
      "    Rule merge: 'Europe' -> 'Europe'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    4 rule-based merge(s)\n",
      "[60] p346 para 60 | +11 ext, 8 kept | rule: 4 merged, 4 new | llm: 4 cand, 4 checked, 0 merged | master: 204e 315r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 1 orphans: Rome\n",
      "    Rule merge: 'Roman Empire' -> 'Roman Empire'\n",
      "    Rule merge: 'Augustus' -> 'Octavian'\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    3 rule-based merge(s)\n",
      "[61] p346 para 61 | +8 ext, 7 kept | rule: 3 merged, 4 new | llm: 4 cand, 4 checked, 0 merged | master: 208e 322r\n",
      "    Skipped 6 rels (entity not found)\n",
      "    Dropped 1 orphans: AD 212\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Senate' -> 'Roman Senate'\n",
      "    2 rule-based merge(s)\n",
      "[62] p347 para 62 | +6 ext, 4 kept | rule: 2 merged, 2 new | llm: 0 cand, 0 checked, 0 merged | master: 210e 324r\n",
      "[63] p347 para 63 | 0 entities after filtering\n",
      "    Rule merge: 'Roman' -> 'Roman'\n",
      "    1 rule-based merge(s)\n",
      "  ** LLM MERGE: Italian + Italians (cos:0.778, lev:0.875)\n",
      "[64] p348 para 64 | +3 ext, 3 kept | rule: 1 merged, 2 new | llm: 2 cand, 2 checked, 1 merged | master: 212e 326r\n",
      "    Skipped 3 rels (entity not found)\n",
      "    Dropped 2 orphans: Virgil, first century AD\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Romans' -> 'Romans'\n",
      "    Rule merge: 'Greek' -> 'Greek'\n",
      "    3 rule-based merge(s)\n",
      "[65] p348 para 65 | +8 ext, 6 kept | rule: 3 merged, 3 new | llm: 3 cand, 3 checked, 0 merged | master: 215e 331r\n",
      "    Skipped 3 rels (entity not found)\n",
      "    Dropped 3 orphans: Roman civilization, neo-Platonism, mystery religions\n",
      "    Rule merge: 'Roman culture' -> 'Roman culture'\n",
      "    Rule merge: 'republic' -> 'Roman republic'\n",
      "    2 rule-based merge(s)\n",
      "  ** LLM MERGE: Greek background + Greek influence (cos:0.793, lev:0.647)\n",
      "[66] p348 para 66 | +11 ext, 8 kept | rule: 2 merged, 6 new | llm: 7 cand, 7 checked, 1 merged | master: 221e 338r\n",
      "    Skipped 6 rels (entity not found)\n",
      "    Dropped 3 orphans: Rome, Indus, Christian basilicas\n",
      "    Rule merge: 'Romans' -> 'Romans'\n",
      "    Rule merge: 'Greeks' -> 'Greeks'\n",
      "    2 rule-based merge(s)\n",
      "[67] p349 para 67 | +9 ext, 6 kept | rule: 2 merged, 4 new | llm: 0 cand, 0 checked, 0 merged | master: 225e 343r\n",
      "    Rule merge: 'Black Sea' -> 'Black Sea'\n",
      "    Rule merge: 'Hadrian’s Wall' -> 'Hadrian’s Wall'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Greece' -> 'Greece'\n",
      "    4 rule-based merge(s)\n",
      "[68] p350 para 68 | +7 ext, 7 kept | rule: 4 merged, 3 new | llm: 2 cand, 2 checked, 0 merged | master: 228e 349r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'empire' -> 'Roman Empire'\n",
      "    2 rule-based merge(s)\n",
      "[69] p350 para 69 | +3 ext, 3 kept | rule: 2 merged, 1 new | llm: 0 cand, 0 checked, 0 merged | master: 229e 351r\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    1 rule-based merge(s)\n",
      "[70] p351 para 70 | +2 ext, 2 kept | rule: 1 merged, 1 new | llm: 1 cand, 1 checked, 0 merged | master: 230e 352r\n",
      "    Dropped 1 orphans: Trajan\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Alexandria' -> 'Hellenistic Alexandria'\n",
      "    Rule merge: 'Carthage' -> 'Carthage'\n",
      "    3 rule-based merge(s)\n",
      "[71] p351 para 71 | +6 ext, 5 kept | rule: 3 merged, 2 new | llm: 0 cand, 0 checked, 0 merged | master: 232e 357r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Rule merge: 'Roman civilization' -> 'Roman civilization'\n",
      "    Rule merge: 'Etruscan' -> 'Etruscan'\n",
      "    2 rule-based merge(s)\n",
      "[72] p351 para 72 | +6 ext, 6 kept | rule: 2 merged, 4 new | llm: 0 cand, 0 checked, 0 merged | master: 236e 365r\n",
      "[73] p354 para 73 | 0 entities after filtering\n",
      "    Rule merge: 'Romans' -> 'Romans'\n",
      "    Rule merge: 'magistrates' -> 'magistrates'\n",
      "    2 rule-based merge(s)\n",
      "  ** LLM MERGE: res publica + Roman Republic (cos:0.484, lev:0.727)\n",
      "[74] p354 para 74 | +4 ext, 4 kept | rule: 2 merged, 2 new | llm: 4 cand, 4 checked, 1 merged | master: 238e 368r\n",
      "    Skipped 7 rels (entity not found)\n",
      "    Dropped 4 orphans: Augustus, Livy, Cicero, Roman\n",
      "[75] p354 para 75 | 0 entities after filtering\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Rule merge: 'Romans' -> 'Romans'\n",
      "    Rule merge: 'Roman Empire' -> 'Roman Empire'\n",
      "    2 rule-based merge(s)\n",
      "[76] p355 para 76 | +6 ext, 6 kept | rule: 2 merged, 4 new | llm: 0 cand, 0 checked, 0 merged | master: 242e 373r\n",
      "    Skipped 8 rels (entity not found)\n",
      "    Dropped 5 orphans: Augustus, Senate, Asia, second century BC, third century AD\n",
      "    Rule merge: 'Roman Empire' -> 'Roman Empire'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    2 rule-based merge(s)\n",
      "[77] p355 para 77 | +8 ext, 3 kept | rule: 2 merged, 1 new | llm: 2 cand, 2 checked, 0 merged | master: 243e 375r\n",
      "[78] p356 para 78 | 0 entities after filtering\n",
      "    Rule merge: 'Greek pantheon' -> 'Greek'\n",
      "    Rule merge: 'Stoic philosophies' -> 'Stoicism'\n",
      "    Rule merge: 'Roman empire' -> 'Roman Empire'\n",
      "    Rule merge: 'Greek civilization' -> 'Greek civilization'\n",
      "    4 rule-based merge(s)\n",
      "[79] p356 para 79 | +5 ext, 5 kept | rule: 4 merged, 1 new | llm: 1 cand, 1 checked, 0 merged | master: 244e 379r\n",
      "    Skipped 1 rels (entity not found)\n",
      "    Dropped 1 orphans: first century AD\n",
      "    Rule merge: 'Roman' -> 'Roman'\n",
      "    1 rule-based merge(s)\n",
      "[80] p356 para 80 | +8 ext, 7 kept | rule: 1 merged, 6 new | llm: 1 cand, 1 checked, 0 merged | master: 250e 384r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 1 orphans: Christianity\n",
      "[81] p357 para 81 | +3 ext, 2 kept | rule: 0 merged, 2 new | llm: 1 cand, 1 checked, 0 merged | master: 252e 385r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 6 orphans: 73 BC, Alexandria, 170 BC, Roman Empire, AD 66, AD 30\n",
      "    Rule merge: 'Roman rule' -> 'Roman rule'\n",
      "    Rule merge: 'Italy' -> 'Italy'\n",
      "    Rule merge: 'Rome' -> 'Romans'\n",
      "    Rule merge: 'Britain' -> 'Britain'\n",
      "    Rule merge: 'Augustus' -> 'Octavian'\n",
      "    Rule merge: 'Jews' -> 'Jews'\n",
      "    Rule merge: 'imperial cult' -> 'imperial cult'\n",
      "    Rule merge: 'Caesar' -> 'Octavian'\n",
      "    Rule merge: 'Trajan' -> 'Trajan'\n",
      "    Rule merge: 'Hadrian' -> 'Hadrian'\n",
      "    10 rule-based merge(s)\n",
      "[82] p357 para 82 | +21 ext, 15 kept | rule: 10 merged, 5 new | llm: 2 cand, 2 checked, 0 merged | master: 257e 397r\n",
      "    Skipped 2 rels (entity not found)\n",
      "    Dropped 2 orphans: Dacia, Pax Romana\n",
      "[83] p358 para 83 | 0 entities after filtering\n",
      "    Skipped 7 rels (entity not found)\n",
      "    Dropped 10 orphans: Roman state, Augustus, Germany, AD 9, cavalry, auxiliaries, capital, camps of the legions, Praetorian Guard, Rome\n",
      "    Rule merge: 'Roman army' -> 'Roman army'\n",
      "    Rule merge: 'provinces' -> 'provinces'\n",
      "    Rule merge: 'twenty-eight legions' -> 'legions'\n",
      "    Rule merge: 'Egypt' -> 'Egypt'\n",
      "    Rule merge: 'procurator of Judaea' -> 'procurator of Judaea'\n",
      "    5 rule-based merge(s)\n",
      "[84] p359 para 84 | +19 ext, 9 kept | rule: 5 merged, 4 new | llm: 4 cand, 4 checked, 0 merged | master: 261e 402r\n",
      "\n",
      "============================================================\n",
      "DONE: 261 master entities, 402 rels\n",
      "LLM calls: 99, merges: 12\n"
     ]
    }
   ],
   "source": [
    "# Incremental pipeline: process paragraphs one at a time into a growing master graph\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=CONFIG[\"embedding_model\"])\n",
    "merge_chain = setup_merge_chain(CONFIG)\n",
    "threshold = CONFIG[\"similarity_threshold\"]\n",
    "method = CONFIG[\"similarity_method\"]\n",
    "lev_threshold = CONFIG[\"levenshtein_threshold\"]\n",
    "\n",
    "master_entities: list[NormalizedEntity] = []\n",
    "master_relationships: list[NormalizedRelationship] = []\n",
    "master_embeddings: np.ndarray | None = None\n",
    "master_entity_order: list[str] = []  # entity IDs matching master_embeddings rows\n",
    "\n",
    "# Union-Find for LLM merges\n",
    "uf_parent: dict[str, str] = {}\n",
    "uf_representative: dict[str, NormalizedEntity] = {}\n",
    "\n",
    "\n",
    "def uf_find(entity_id: str) -> str:\n",
    "    \"\"\"Find root of entity's group with path compression.\"\"\"\n",
    "    while uf_parent[entity_id] != entity_id:\n",
    "        uf_parent[entity_id] = uf_parent[uf_parent[entity_id]]\n",
    "        entity_id = uf_parent[entity_id]\n",
    "    return entity_id\n",
    "\n",
    "\n",
    "def uf_union(id1: str, id2: str, merged_entity: EntityWithId | None):\n",
    "    \"\"\"Union two groups. Update representative with merged entity info if provided.\"\"\"\n",
    "    root1, root2 = uf_find(id1), uf_find(id2)\n",
    "    if root1 == root2:\n",
    "        return\n",
    "    uf_parent[root2] = root1\n",
    "    rep, other = uf_representative[root1], uf_representative[root2]\n",
    "    if merged_entity:\n",
    "        updated = NormalizedEntity(\n",
    "            id=rep.id, name=merged_entity.name, type=merged_entity.type,\n",
    "            subtype=merged_entity.subtype,\n",
    "            aliases=list(set(rep.aliases + other.aliases + (merged_entity.aliases or []))),\n",
    "            description=merged_entity.description or rep.description,\n",
    "            attributes={**(rep.attributes or {}), **(other.attributes or {}), **(merged_entity.attributes or {})},\n",
    "            source_paragraph_ids=list(set(rep.source_paragraph_ids + other.source_paragraph_ids)),\n",
    "            occurrence_count=rep.occurrence_count + other.occurrence_count,\n",
    "            merged_from_ids=list(set(rep.merged_from_ids + other.merged_from_ids)),\n",
    "            relationship_ids=list(set(rep.relationship_ids + other.relationship_ids)),\n",
    "        )\n",
    "    else:\n",
    "        updated = NormalizedEntity(\n",
    "            id=rep.id, name=rep.name, type=rep.type, subtype=rep.subtype,\n",
    "            aliases=list(set(rep.aliases + other.aliases)),\n",
    "            description=f\"{rep.description} | {other.description}\".strip(\" | \"),\n",
    "            attributes={**(rep.attributes or {}), **(other.attributes or {})},\n",
    "            source_paragraph_ids=list(set(rep.source_paragraph_ids + other.source_paragraph_ids)),\n",
    "            occurrence_count=rep.occurrence_count + other.occurrence_count,\n",
    "            merged_from_ids=list(set(rep.merged_from_ids + other.merged_from_ids)),\n",
    "            relationship_ids=list(set(rep.relationship_ids + other.relationship_ids)),\n",
    "        )\n",
    "    uf_representative[root1] = updated\n",
    "\n",
    "\n",
    "all_llm_results = []\n",
    "print(f\"Candidate finding: {method} (threshold: {lev_threshold if method == 'levenshtein' else threshold})\")\n",
    "print(f\"Tracking both cosine and levenshtein similarity for all candidates\\n\")\n",
    "\n",
    "for i, para in enumerate(paragraphs):\n",
    "    # 1. Extract\n",
    "    result = extract_entities(para[\"text\"], para[\"id\"], CONFIG)\n",
    "\n",
    "    # 2. Assign IDs + drop orphans\n",
    "    entities, relationships = assign_ids_single(result)\n",
    "\n",
    "    if not entities:\n",
    "        print(f\"[{i}] p{para['page']} para {para['paragraph_index']} | 0 entities after filtering\")\n",
    "        continue\n",
    "\n",
    "    # 3. Rule-based merge into master\n",
    "    n_before = len(master_entities)\n",
    "    master_entities, master_relationships, newly_added = merge_into_master_rule_based(\n",
    "        entities, relationships, master_entities, master_relationships,\n",
    "    )\n",
    "    n_rule = len(entities) - len(newly_added)\n",
    "\n",
    "    # 4. Find candidates and run LLM merge\n",
    "    n_candidates = 0\n",
    "    n_llm_checked = 0\n",
    "    n_llm_merged = 0\n",
    "\n",
    "    if newly_added:\n",
    "        # Initialize UF entries for new entities\n",
    "        for ne in newly_added:\n",
    "            uf_parent[ne.id] = ne.id\n",
    "            uf_representative[ne.id] = ne\n",
    "\n",
    "        newly_added_ids = {e.id for e in newly_added}\n",
    "\n",
    "        # Always embed new entities (needed for cosine score tracking)\n",
    "        new_texts = [create_entity_text(e) for e in newly_added]\n",
    "        new_embs = np.array(embeddings_model.embed_documents(new_texts))\n",
    "\n",
    "        # Precompute cosine sim matrix against existing master\n",
    "        cosine_sim_matrix = None\n",
    "        if master_embeddings is not None and len(master_entity_order) > 0:\n",
    "            cosine_sim_matrix = cosine_similarity(new_embs, master_embeddings)\n",
    "\n",
    "        # Index lookups for cosine score retrieval\n",
    "        new_id_to_idx = {e.id: i for i, e in enumerate(newly_added)}\n",
    "        master_id_to_idx = {eid: i for i, eid in enumerate(master_entity_order)}\n",
    "\n",
    "        # --- Find candidates: branch by method ---\n",
    "        candidates = []\n",
    "        if method == \"cosine\":\n",
    "            if cosine_sim_matrix is not None:\n",
    "                master_lookup = {e.id: e for e in master_entities}\n",
    "                existing_entities = [master_lookup[eid] for eid in master_entity_order]\n",
    "                candidates = find_candidates_against_master(\n",
    "                    newly_added, new_embs, existing_entities, master_embeddings, threshold,\n",
    "                )\n",
    "        elif method == \"levenshtein\":\n",
    "            existing = [e for e in master_entities if e.id not in newly_added_ids]\n",
    "            if existing:\n",
    "                candidates = find_candidates_levenshtein(newly_added, existing, lev_threshold)\n",
    "\n",
    "        n_candidates = len(candidates)\n",
    "\n",
    "        # 5. LLM merge on candidates — track both similarity metrics\n",
    "        for c in candidates[: CONFIG[\"max_llm_candidates\"]]:\n",
    "            ne, me = c[\"new_entity\"], c[\"master_entity\"]\n",
    "\n",
    "            root_new, root_master = uf_find(ne.id), uf_find(me.id)\n",
    "            if root_new == root_master:\n",
    "                continue\n",
    "\n",
    "            rep_new = uf_representative[root_new]\n",
    "            rep_master = uf_representative[root_master]\n",
    "            decision = decide_entity_merge(rep_new, rep_master, merge_chain)\n",
    "            n_llm_checked += 1\n",
    "\n",
    "            # Compute both similarity scores on the original candidate entities\n",
    "            ne_names = [ne.name] + ne.aliases\n",
    "            me_names = [me.name] + me.aliases\n",
    "            lev_score = max(\n",
    "                levenshtein_similarity(n1, n2) for n1 in ne_names for n2 in me_names\n",
    "            )\n",
    "\n",
    "            cosine_score = None\n",
    "            ni = new_id_to_idx.get(ne.id)\n",
    "            mi = master_id_to_idx.get(me.id)\n",
    "            if cosine_sim_matrix is not None and ni is not None and mi is not None:\n",
    "                cosine_score = float(cosine_sim_matrix[ni, mi])\n",
    "\n",
    "            all_llm_results.append({\n",
    "                \"paragraph_idx\": i,\n",
    "                \"page\": para[\"page\"],\n",
    "                \"entity1_name\": rep_new.name,\n",
    "                \"entity2_name\": rep_master.name,\n",
    "                \"cosine_similarity\": cosine_score,\n",
    "                \"levenshtein_similarity\": lev_score,\n",
    "                \"should_merge\": decision.should_merge,\n",
    "                \"confidence\": decision.confidence,\n",
    "                \"reasoning\": decision.reasoning,\n",
    "            })\n",
    "\n",
    "            if decision.should_merge:\n",
    "                uf_union(ne.id, me.id, decision.merged_entity)\n",
    "                n_llm_merged += 1\n",
    "                print(f\"  ** LLM MERGE: {rep_new.name} + {rep_master.name} (cos:{cosine_score:.3f}, lev:{lev_score:.3f})\")\n",
    "\n",
    "        # 6. Always update master embeddings\n",
    "        if master_embeddings is None:\n",
    "            master_embeddings = new_embs\n",
    "        else:\n",
    "            master_embeddings = np.vstack([master_embeddings, new_embs])\n",
    "        master_entity_order.extend(e.id for e in newly_added)\n",
    "\n",
    "    print(\n",
    "        f\"[{i}] p{para['page']} para {para['paragraph_index']} | \"\n",
    "        f\"+{len(result.entities)} ext, {len(entities)} kept | \"\n",
    "        f\"rule: {n_rule} merged, {len(newly_added)} new | \"\n",
    "        f\"llm: {n_candidates} cand, {n_llm_checked} checked, {n_llm_merged} merged | \"\n",
    "        f\"master: {len(master_entities)}e {len(master_relationships)}r\"\n",
    "    )\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DONE: {len(master_entities)} master entities, {len(master_relationships)} rels\")\n",
    "print(f\"LLM calls: {len(all_llm_results)}, merges: {sum(1 for r in all_llm_results if r['should_merge'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final: 249 entities, 402 relationships\n",
      "Pipeline: 85 paragraphs -> 261 after rule-based -> 249 final (12 LLM merges)\n"
     ]
    }
   ],
   "source": [
    "# Build final entities from Union-Find groups (apply LLM merges to master state)\n",
    "\n",
    "groups: dict[str, list[str]] = defaultdict(list)\n",
    "for eid in uf_parent:\n",
    "    root = uf_find(eid)\n",
    "    groups[root].append(eid)\n",
    "\n",
    "final_entities: list[NormalizedEntity] = []\n",
    "master_id_to_final_id: dict[str, str] = {}\n",
    "\n",
    "for root_id, member_ids in groups.items():\n",
    "    rep = uf_representative[root_id]\n",
    "    final_id = str(uuid_module.uuid4())\n",
    "\n",
    "    final_entity = NormalizedEntity(\n",
    "        id=final_id, name=rep.name, type=rep.type, subtype=rep.subtype,\n",
    "        aliases=rep.aliases, description=rep.description,\n",
    "        attributes=rep.attributes if rep.attributes else None,\n",
    "        source_paragraph_ids=rep.source_paragraph_ids,\n",
    "        occurrence_count=rep.occurrence_count,\n",
    "        merged_from_ids=rep.merged_from_ids,\n",
    "        relationship_ids=[],\n",
    "    )\n",
    "    final_entities.append(final_entity)\n",
    "    for mid in member_ids:\n",
    "        master_id_to_final_id[mid] = final_id\n",
    "\n",
    "# Remap relationships from master IDs to final IDs\n",
    "final_relationships: list[NormalizedRelationship] = []\n",
    "final_entity_lookup = {e.id: e for e in final_entities}\n",
    "\n",
    "for rel in master_relationships:\n",
    "    final_source = master_id_to_final_id.get(rel.source_id)\n",
    "    final_target = master_id_to_final_id.get(rel.target_id)\n",
    "    if final_source and final_target:\n",
    "        final_rel = NormalizedRelationship(\n",
    "            id=rel.id, source_id=final_source, target_id=final_target,\n",
    "            source_entity_name=rel.source_entity_name, target_entity_name=rel.target_entity_name,\n",
    "            relation_type=rel.relation_type, temporal_context=rel.temporal_context,\n",
    "            confidence=rel.confidence, paragraph_id=rel.paragraph_id,\n",
    "        )\n",
    "        final_relationships.append(final_rel)\n",
    "        if final_source in final_entity_lookup:\n",
    "            final_entity_lookup[final_source].relationship_ids.append(rel.id)\n",
    "        if final_target in final_entity_lookup:\n",
    "            final_entity_lookup[final_target].relationship_ids.append(rel.id)\n",
    "\n",
    "llm_merge_count = sum(1 for r in all_llm_results if r[\"should_merge\"])\n",
    "print(f\"Final: {len(final_entities)} entities, {len(final_relationships)} relationships\")\n",
    "print(f\"Pipeline: {len(paragraphs)} paragraphs -> {len(master_entities)} after rule-based -> {len(final_entities)} final ({llm_merge_count} LLM merges)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 99 LLM check results to llm_normalization_results_cos_and_lev_2.csv\n",
      "  Merges: 12, Non-merges: 87\n",
      "  Cosine range:      0.224 - 0.862\n",
      "  Levenshtein range: 0.600 - 0.923\n"
     ]
    }
   ],
   "source": [
    "# Export LLM normalization results for analysis\n",
    "df_llm = pd.DataFrame(all_llm_results)\n",
    "export_path = Path(\"llm_normalization_results_cos_and_lev_2.csv\")\n",
    "df_llm.to_csv(export_path, index=False)\n",
    "print(f\"Exported {len(df_llm)} LLM check results to {export_path}\")\n",
    "print(f\"  Merges: {df_llm['should_merge'].sum()}, Non-merges: {(~df_llm['should_merge']).sum()}\")\n",
    "print(f\"  Cosine range:      {df_llm['cosine_similarity'].min():.3f} - {df_llm['cosine_similarity'].max():.3f}\")\n",
    "print(f\"  Levenshtein range: {df_llm['levenshtein_similarity'].min():.3f} - {df_llm['levenshtein_similarity'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect final normalized entities\n",
    "print(\"Final entities (sorted by occurrence):\")\n",
    "for e in sorted(final_entities, key=lambda x: x.occurrence_count, reverse=True):\n",
    "    aliases_str = f\" (aka {', '.join(e.aliases[:5])})\" if e.aliases else \"\"\n",
    "    merged_str = f\" [merged from {len(e.merged_from_ids)}]\" if len(e.merged_from_ids) > 1 else \"\"\n",
    "    print(f\"  {e.name}{aliases_str}: {e.occurrence_count} occ, {len(e.relationship_ids)} rels [{e.type}]{merged_str}\")\n",
    "\n",
    "# Show what LLM normalization caught that rule-based missed\n",
    "llm_merges = [r for r in all_llm_results if r[\"should_merge\"]]\n",
    "if llm_merges:\n",
    "    print(f\"\\nLLM caught {len(llm_merges)} additional merge(s) beyond rule-based:\")\n",
    "    for r in llm_merges:\n",
    "        print(f\"  {r['entity1_name']} + {r['entity2_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knowledge_graph(\n",
    "    entities: list[NormalizedEntity],\n",
    "    relationships: list[NormalizedRelationship],\n",
    ") -> nx.DiGraph:\n",
    "    \"\"\"Build a directed graph from normalized entities and relationships.\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for entity in entities:\n",
    "        G.add_node(\n",
    "            entity.id,\n",
    "            name=entity.name,\n",
    "            entity_type=entity.type,\n",
    "            subtype=entity.subtype,\n",
    "            aliases=entity.aliases,\n",
    "            description=entity.description,\n",
    "            occurrence_count=entity.occurrence_count,\n",
    "            merged_from_ids=entity.merged_from_ids,\n",
    "            paragraph_ids=entity.source_paragraph_ids,\n",
    "        )\n",
    "\n",
    "    for rel in relationships:\n",
    "        if rel.source_id in G and rel.target_id in G:\n",
    "            if G.has_edge(rel.source_id, rel.target_id):\n",
    "                edge_data = G[rel.source_id][rel.target_id]\n",
    "                if rel.relation_type not in edge_data.get(\"relation_types\", []):\n",
    "                    edge_data.setdefault(\"relation_types\", []).append(rel.relation_type)\n",
    "                edge_data.setdefault(\"original_name_pairs\", []).append(\n",
    "                    (rel.source_entity_name, rel.target_entity_name)\n",
    "                )\n",
    "            else:\n",
    "                G.add_edge(\n",
    "                    rel.source_id,\n",
    "                    rel.target_id,\n",
    "                    relation_type=rel.relation_type,\n",
    "                    relation_types=[rel.relation_type],\n",
    "                    temporal_context=rel.temporal_context,\n",
    "                    confidence=rel.confidence,\n",
    "                    source_paragraph=rel.paragraph_id,\n",
    "                    source_entity_name=rel.source_entity_name,\n",
    "                    target_entity_name=rel.target_entity_name,\n",
    "                    original_name_pairs=[(rel.source_entity_name, rel.target_entity_name)],\n",
    "                )\n",
    "\n",
    "    print(f\"Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "    return G\n",
    "\n",
    "\n",
    "G = build_knowledge_graph(final_entities, final_relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph stats\n",
    "print(f\"Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Edges: {G.number_of_edges()}\")\n",
    "if G.number_of_nodes() > 0:\n",
    "    degrees = dict(G.degree())\n",
    "    print(f\"Avg degree: {sum(degrees.values()) / len(degrees):.2f}\")\n",
    "    print(f\"Density: {nx.density(G):.3f}\")\n",
    "\n",
    "    print(f\"\\nTop entities by degree:\")\n",
    "    for node_id, degree in sorted(degrees.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"  {G.nodes[node_id]['name']}: degree {degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE_COLORS = {\n",
    "    \"person\": \"#FF6B6B\",\n",
    "    \"place\": \"#4ECDC4\",\n",
    "    \"collective_entity\": \"#45B7D1\",\n",
    "    \"event\": \"#FFA07A\",\n",
    "    \"temporal\": \"#98D8C8\",\n",
    "    \"cultural\": \"#C7CEEA\",\n",
    "}\n",
    "\n",
    "\n",
    "def visualize_with_pyvis(\n",
    "    G: nx.DiGraph,\n",
    "    entities: list[NormalizedEntity],\n",
    "    relationships: list[NormalizedRelationship],\n",
    "    output_file: str = \"knowledge_graph_v2.html\",\n",
    ") -> Network:\n",
    "    \"\"\"Create interactive PyVis visualization. Edges show original entity names.\"\"\"\n",
    "    net = Network(\n",
    "        height=\"900px\", width=\"100%\", directed=True, notebook=True,\n",
    "        bgcolor=\"#F8F9FA\", font_color=\"#333333\",\n",
    "    )\n",
    "    net.set_options(\"\"\"\n",
    "    {\n",
    "        \"physics\": {\n",
    "            \"enabled\": true,\n",
    "            \"forceAtlas2Based\": {\n",
    "                \"gravitationalConstant\": -50,\n",
    "                \"centralGravity\": 0.01,\n",
    "                \"springLength\": 200,\n",
    "                \"springConstant\": 0.08\n",
    "            },\n",
    "            \"maxVelocity\": 50,\n",
    "            \"solver\": \"forceAtlas2Based\",\n",
    "            \"timestep\": 0.35,\n",
    "            \"stabilization\": {\"iterations\": 150}\n",
    "        },\n",
    "        \"interaction\": {\n",
    "            \"hover\": true, \"tooltipDelay\": 100,\n",
    "            \"navigationButtons\": true, \"keyboard\": true\n",
    "        }\n",
    "    }\n",
    "    \"\"\")\n",
    "\n",
    "    entity_lookup = {e.id: e for e in entities}\n",
    "\n",
    "    # Add nodes\n",
    "    for entity in entities:\n",
    "        color = TYPE_COLORS.get(entity.type, \"#CCCCCC\")\n",
    "        size = 15 + (entity.occurrence_count * 5)\n",
    "\n",
    "        title = f\"<b>{entity.name}</b><br>\"\n",
    "        title += f\"Type: {entity.type}\"\n",
    "        if entity.subtype:\n",
    "            title += f\" ({entity.subtype})\"\n",
    "        title += f\"<br>Occurrences: {entity.occurrence_count}\"\n",
    "        title += f\"<br>Relationships: {len(entity.relationship_ids)}\"\n",
    "        if entity.aliases:\n",
    "            title += f\"<br>Aliases: {', '.join(entity.aliases[:5])}\"\n",
    "        if entity.description:\n",
    "            desc = entity.description[:150] + \"...\" if len(entity.description) > 150 else entity.description\n",
    "            title += f\"<br><br>{desc}\"\n",
    "        if len(entity.merged_from_ids) > 1:\n",
    "            title += f\"<br><br>Merged from {len(entity.merged_from_ids)} entities\"\n",
    "\n",
    "        net.add_node(\n",
    "            entity.id, label=entity.name, title=title,\n",
    "            color=color, size=size, font={\"size\": 14},\n",
    "            borderWidth=2,\n",
    "        )\n",
    "\n",
    "    # Add edges with original entity names\n",
    "    for rel in relationships:\n",
    "        if rel.source_id in entity_lookup and rel.target_id in entity_lookup:\n",
    "            label = f\"{rel.source_entity_name} \\u2192 {rel.target_entity_name}\"\n",
    "            label += f\"\\n{rel.relation_type.replace('-', ' ').replace('_', ' ')}\"\n",
    "\n",
    "            title = f\"{rel.source_entity_name} \\u2192 {rel.target_entity_name}<br>\"\n",
    "            title += f\"Relationship: {rel.relation_type}<br>\"\n",
    "            title += f\"Normalized: {entity_lookup[rel.source_id].name} \\u2192 {entity_lookup[rel.target_id].name}\"\n",
    "            if rel.temporal_context:\n",
    "                title += f\"<br>When: {rel.temporal_context}\"\n",
    "\n",
    "            net.add_edge(\n",
    "                rel.source_id, rel.target_id,\n",
    "                label=label, title=title, arrows=\"to\",\n",
    "                color={\"color\": \"#888888\", \"highlight\": \"#333333\"},\n",
    "                width=2, font={\"size\": 10, \"align\": \"middle\"},\n",
    "            )\n",
    "\n",
    "    net.save_graph(output_file)\n",
    "    print(f\"Saved visualization to {output_file}\")\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = \"knowledge_graph_v2_rome.html\"\n",
    "net = visualize_with_pyvis(G, final_entities, final_relationships, output_file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the visualization\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# HTML(filename=\"knowledge_graph_v2_b.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "history-book-py3.11 (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
